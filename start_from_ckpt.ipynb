{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bf76c30-4cfb-42d2-ab59-8ff96dfb74e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "815d6199-17b2-4e8f-aede-60ae3c35d4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home1/zzhang201@kgi.edu/GAN/zzGAN/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29b016c6-6cd8-4b00-b56d-268d1abbd146",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-16 17:13:26.081816: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-16 17:13:26.116037: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# import tensorflow_gan as tfgan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c01e5ef2-45e5-4008-a99a-c108ba64dfa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF version: 2.16.1\n",
      "GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "print(\"TF version:\", tf.__version__)\n",
    "print(\"GPUs:\", tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f7a9d9f-d845-44f6-83e2-6bfb7996d386",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import jensenshannon\n",
    "import matplotlib.ticker as ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c767d0e-858f-4169-9d34-6951dbe77a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home1/zzhang201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import umap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33435abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import datetime\n",
    "import platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6785f0f-c59d-4899-b738-2ee049d2ecf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import gan.documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2052766",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gan.models import get_model, get_specific_hooks\n",
    "from gan.parameters import get_flags\n",
    "from gan.documentation import setup_logdir, get_properties\n",
    "from gan.documentation import print_run_meta_data, add_model_metadata\n",
    "from tensorflow.keras import mixed_precision\n",
    "from tensorflow.keras.mixed_precision import LossScaleOptimizer\n",
    "# Enable global mixed precision policy\n",
    "mixed_precision.set_global_policy('mixed_float16')\n",
    "from protein.quality_gates import quality_losses, anarci_quality_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0040c371-8a1c-4349-a3f1-b8bcc2b2ec73",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FakeFlags:\n",
    "    # General model setup\n",
    "    model_type = 'wgan'\n",
    "    architecture = 'gumbel'\n",
    "    batch_size = 64\n",
    "    z_dim = 128\n",
    "    gf_dim = 64\n",
    "    df_dim = 64\n",
    "    dim = gf_dim\n",
    "    attn_pos = 2\n",
    "\n",
    "    # Kernel and dilation config\n",
    "    kernel_height = 3\n",
    "    kernel_width = 3\n",
    "    dilation_rate = 2\n",
    "    pooling = 'conv'\n",
    "\n",
    "    # Optional: logging / save frequency\n",
    "    name = 'multiG_attn_adjusted_embed'\n",
    "    steps = 200000\n",
    "    save_summary_steps = 1000\n",
    "    save_checkpoint_sec = 5000\n",
    "\n",
    "    # Optimizer settings\n",
    "    generator_learning_rate = 1e-4\n",
    "    discriminator_learning_rate = 1e-4\n",
    "    beta1 = 0.5\n",
    "    beta2 = 0.9\n",
    "\n",
    "    # Dataset & file structure\n",
    "    dataset = 'zz'\n",
    "    seq_length = 160\n",
    "    logdir = '/home1/zzhang201@kgi.edu/GAN/zzGAN/logs/zz'\n",
    "    # properties_file = 'properties.json'\n",
    "\n",
    "    # Misc\n",
    "    seed = 950806\n",
    "    is_train = True\n",
    "    multid_schedule = 20000\n",
    "    d_step = 3\n",
    "    shuffle_buffer_size = 1000\n",
    "    label_noise_level = 0.0\n",
    "    noise_level = 0.0\n",
    "\n",
    "    def flag_values_dict(self):\n",
    "        return {k: getattr(self, k) for k in dir(self)\n",
    "                if not k.startswith(\"__\") and not callable(getattr(self, k))}\n",
    "FLAGS = FakeFlags()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339bfacc-054f-48b8-b491-c4bbc50bb11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(FLAGS.seed)\n",
    "np.random.seed(FLAGS.seed)\n",
    "tf.random.set_seed(FLAGS.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "defe8e17-ad68-48a9-9124-8c8968a7b581",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_flags(flags, log_dir, filename=\"flags.json\"):\n",
    "    \"\"\"Save FLAGS to a JSON file in the log directory.\"\"\"\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "    file_path = os.path.join(log_dir, filename)\n",
    "\n",
    "    with open(file_path, \"w\") as f:\n",
    "        json.dump(flags.flag_values_dict(), f, indent=4)\n",
    "    \n",
    "    print(f\"[FLAGS] Saved flags to {file_path}\")\n",
    "\n",
    "def load_flags(log_dir, filename=\"flags.json\"):\n",
    "    \"\"\"Load FLAGS from JSON file and return as a FakeFlags object.\"\"\"\n",
    "    file_path = os.path.join(log_dir, filename)\n",
    "\n",
    "    if not os.path.exists(file_path):\n",
    "        raise FileNotFoundError(f\"[FLAGS] No flags file found at {file_path}\")\n",
    "\n",
    "    with open(file_path, \"r\") as f:\n",
    "        flag_dict = json.load(f)\n",
    "\n",
    "    # Create a new FakeFlags object and set attributes\n",
    "    loaded_flags = FakeFlags()\n",
    "    for k, v in flag_dict.items():\n",
    "        setattr(loaded_flags, k, v)\n",
    "\n",
    "    print(f\"[FLAGS] Loaded flags from {file_path}\")\n",
    "    return loaded_flags\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "855a778b-e9af-484d-b972-14e5ca953f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_example(example_proto, seq_len=160, vocab_size=21):\n",
    "    feature_description = {\n",
    "        \"sequence\": tf.io.VarLenFeature(tf.int64),\n",
    "        \"label\": tf.io.FixedLenFeature([], tf.int64),  # parsed but unused\n",
    "    }\n",
    "    parsed = tf.io.parse_single_example(example_proto, feature_description)\n",
    "\n",
    "    sequence = tf.sparse.to_dense(parsed[\"sequence\"])\n",
    "    sequence = tf.cast(sequence, tf.int32)\n",
    "\n",
    "    # Clip or pad to fixed length\n",
    "    sequence = sequence[:seq_len]\n",
    "    paddings = [[0, tf.maximum(0, seq_len - tf.shape(sequence)[0])]]\n",
    "    sequence = tf.pad(sequence, paddings)\n",
    "\n",
    "    # One-hot encode → [seq_len, vocab_size] float32\n",
    "    one_hot = tf.one_hot(sequence, vocab_size)\n",
    "    return one_hot\n",
    "\n",
    "def load_tfrecord_dataset(\n",
    "    tfrecord_dir,\n",
    "    batch_size=8,\n",
    "    seq_len=160,\n",
    "    vocab_size=21,\n",
    "    shuffle_buffer=10000,\n",
    "    seed=1337,\n",
    "    deterministic=True,\n",
    "    cycle_length=4,\n",
    "    drop_remainder=True,\n",
    "):\n",
    "    # Stable file order (DO NOT shuffle here)\n",
    "    files = sorted(tf.io.gfile.glob(os.path.join(tfrecord_dir, \"*.tfrecords\")))\n",
    "    if not files:\n",
    "        raise FileNotFoundError(f\"No .tfrecords under {tfrecord_dir}\")\n",
    "\n",
    "    ds_files = tf.data.Dataset.from_tensor_slices(files)\n",
    "\n",
    "    # Deterministic interleave over files\n",
    "    ds = ds_files.interleave(\n",
    "        lambda p: tf.data.TFRecordDataset(p),\n",
    "        cycle_length=cycle_length,\n",
    "        num_parallel_calls=tf.data.AUTOTUNE,\n",
    "        deterministic=deterministic,\n",
    "    )\n",
    "\n",
    "    ds = ds.map(\n",
    "        lambda ex: parse_example(ex, seq_len, vocab_size),\n",
    "        num_parallel_calls=tf.data.AUTOTUNE,\n",
    "    )\n",
    "\n",
    "    # Seeded shuffle; NO reshuffle each epoch → same order every run\n",
    "    if shuffle_buffer and shuffle_buffer > 0:\n",
    "        ds = ds.shuffle(\n",
    "            buffer_size=shuffle_buffer,\n",
    "            seed=seed,\n",
    "            reshuffle_each_iteration=False,\n",
    "        )\n",
    "\n",
    "    # Infinite stream with fixed batch shapes\n",
    "    ds = ds.batch(batch_size, drop_remainder=drop_remainder)\n",
    "    ds = ds.repeat()\n",
    "\n",
    "    # Enforce deterministic behavior at the pipeline level if requested\n",
    "    opts = tf.data.Options()\n",
    "    opts.deterministic = deterministic\n",
    "    ds = ds.with_options(opts)\n",
    "\n",
    "    ds = ds.prefetch(tf.data.AUTOTUNE)\n",
    "    return ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "62232c39-2f12-42bd-97ec-7bf5e22feb59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-16 17:13:36.696487: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43622 MB memory:  -> device: 0, name: NVIDIA L40S, pci bus id: 0000:21:00.0, compute capability: 8.9\n",
      "2025-09-16 17:13:36.697018: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 43622 MB memory:  -> device: 1, name: NVIDIA L40S, pci bus id: 0000:e1:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 160, 21)\n"
     ]
    }
   ],
   "source": [
    "dataset = load_tfrecord_dataset(\n",
    "    tfrecord_dir=\"/home1/zzhang201@kgi.edu/GAN/zzGAN/gan/data/zz/train\",\n",
    "    batch_size=FLAGS.batch_size,\n",
    "    seq_len=160,\n",
    "    seed=FLAGS.seed,\n",
    "    deterministic=True,  # flip to False if you want max throughput\n",
    ")\n",
    "\n",
    "batch = next(iter(dataset))\n",
    "print(batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d42fcf4c-bf19-41d1-a16a-cf19ec977455",
   "metadata": {},
   "outputs": [],
   "source": [
    "# properties = get_properties(FLAGS)\n",
    "# properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cd67a492-dcfe-4ae6-a64d-326f135891c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gumbel'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FLAGS.architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "50634560-dffc-4bae-9eed-8cc2bc7e1580",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "log_dir = os.path.join(FLAGS.logdir, FLAGS.name, timestamp)\n",
    "\n",
    "noise = tf.random.normal([FLAGS.batch_size, FLAGS.z_dim])\n",
    "model = get_model(FLAGS, log_dir, noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3b55e219-dcf8-409f-b93c-ec1c4c397f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_discriminator_step(generator, discriminator, d_optimizer, real_batch, noise_dim, lambda_gp=10.0):\n",
    "    batch_size = tf.shape(real_batch)[0]\n",
    "    real_batch = tf.expand_dims(real_batch, axis=1)\n",
    "    noise = tf.random.normal([batch_size, noise_dim])\n",
    "    fake_batch = generator(noise, training=True, return_hard=False)\n",
    "\n",
    "    with tf.GradientTape() as disc_tape:\n",
    "        real_logits = discriminator(real_batch, training=True)\n",
    "        fake_logits = discriminator(fake_batch, training=True)\n",
    "        d_loss = tf.reduce_mean(fake_logits) - tf.reduce_mean(real_logits)\n",
    "\n",
    "        # Gradient penalty\n",
    "        alpha = tf.random.uniform([batch_size, 1, 1, 1], 0.0, 1.0)\n",
    "        interpolated = alpha * real_batch + (1. - alpha) * fake_batch\n",
    "        with tf.GradientTape() as gp_tape:\n",
    "            gp_tape.watch(interpolated)\n",
    "            interp_logits = discriminator(interpolated, training=True)\n",
    "        grads = gp_tape.gradient(interp_logits, [interpolated])[0]\n",
    "        grads_flat = tf.reshape(grads, [batch_size, -1])\n",
    "        grad_norm = tf.norm(grads_flat, axis=1)\n",
    "        gp = tf.reduce_mean((grad_norm - 1.0) ** 2)\n",
    "        d_loss += lambda_gp * gp\n",
    "\n",
    "    d_grads = disc_tape.gradient(d_loss, discriminator.trainable_variables)\n",
    "    d_grad_norm = tf.linalg.global_norm(d_grads)\n",
    "    d_optimizer.apply_gradients(zip(d_grads, discriminator.trainable_variables))\n",
    "\n",
    "    return d_loss, d_grad_norm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e2a8d061-a7e7-48f3-b7ad-c13bce2a65f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_generator_step(generator, discriminator, g_optimizer, noise_dim):\n",
    "    noise = tf.random.normal([FLAGS.batch_size, noise_dim])\n",
    "    with tf.GradientTape() as gen_tape:\n",
    "        fake_batch = generator(noise, training=True)\n",
    "        fake_logits = discriminator(fake_batch, training=True)\n",
    "        # After computing generator logits\n",
    "        logits = model.g_model.last_logits  # You may need to store this in call()\n",
    "        softmax = tf.nn.softmax(logits, axis=-1)\n",
    "        entropy = -tf.reduce_mean(tf.reduce_sum(softmax * tf.math.log(softmax + 1e-8), axis=-1))\n",
    "        g_loss = -tf.reduce_mean(fake_logits)\n",
    "        g_loss += 0.01 * entropy  # weight of bonus (tunable)\n",
    "        \n",
    "    g_grads = gen_tape.gradient(g_loss, generator.trainable_variables)\n",
    "    g_grad_norm = tf.linalg.global_norm(g_grads)\n",
    "    g_optimizer.apply_gradients(zip(g_grads, generator.trainable_variables))\n",
    "\n",
    "    return g_loss, g_grad_norm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "06c3d7bb-f364-48c6-8597-65331aa7effd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FLAGS] Saved flags to /home1/zzhang201@kgi.edu/GAN/zzGAN/logs/zz/multiG_attn_adjusted_embed/20250916-171337/summaries/flags.json\n"
     ]
    }
   ],
   "source": [
    "# === Setup ===\n",
    "MAX_STEPS = FLAGS.steps\n",
    "NOISE_DIM = 128  # Confirm this matches your model config\n",
    "\n",
    "checkpoint_dir = os.path.join(log_dir, \"checkpoints\")\n",
    "summary_dir = os.path.join(log_dir, \"summaries\")\n",
    "attn_dir = os.path.join(log_dir, \"attn_scores\")\n",
    "# config_dir = os.path.join(FLAGS.logdir, FLAGS.name, \"setup\")\n",
    "\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "os.makedirs(summary_dir, exist_ok=True)\n",
    "os.makedirs(attn_dir, exist_ok=True)\n",
    "\n",
    "summary_writer = tf.summary.create_file_writer(summary_dir)\n",
    "save_flags(FLAGS, summary_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d89b9a-199b-44e8-990c-ac7c986f9dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import csv\n",
    "import re\n",
    "\n",
    "# Where to put generated sequences for this run\n",
    "SEQ_DIR = log_dir / \"generated_sequences\" # keep alongside your \"summaries\"\n",
    "SEQ_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "FASTA_PATH = SEQ_DIR / \"generated_sequences.fasta\"\n",
    "INDEX_PATH = SEQ_DIR / \"generated_sequences_index.csv\"\n",
    "\n",
    "# Write CSV header once if file is new\n",
    "if not INDEX_PATH.exists():\n",
    "    with open(INDEX_PATH, \"w\", newline=\"\") as f:\n",
    "        csv.writer(f).writerow([\"step\",\"seq_idx\",\"length\"])\n",
    "        \n",
    "AA = set(\"ACDEFGHIKLMNPQRSTVWYXBZ-\")\n",
    "def sanitize_seq(s: str) -> str:\n",
    "    s = re.sub(r\"\\s+\", \"\", s).upper()\n",
    "    return \"\".join(ch for ch in s if ch in AA)\n",
    "\n",
    "def append_generated_sequences(step: int, sequences):\n",
    "    \"\"\"Append sequences to FASTA + index CSV. Header stores the step + idx.\"\"\"\n",
    "    with open(FASTA_PATH, \"a\") as ffa, open(INDEX_PATH, \"a\", newline=\"\") as fcsv:\n",
    "        w = csv.writer(fcsv)\n",
    "        for i, s in enumerate(sequences):\n",
    "            seq = sanitize_seq(s)\n",
    "            header = f\"step{step:06d}_idx{i}\"\n",
    "            ffa.write(f\">{header}\\n{seq}\\n\")\n",
    "            w.writerow([step, i, len(seq)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "67e4bb3d-5e35-400c-b71e-4549080cc6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = tf.train.Checkpoint(\n",
    "    generator=model.g_model,\n",
    "    discriminator=model.d_model,\n",
    "    g_optimizer=model.g_optim,\n",
    "    d_optimizer=model.d_optim,\n",
    "    step=model.g_model.global_step\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a1ee0b04-0f8e-4302-8e2d-0f10f4820981",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load old models\n",
    "# ckpt.restore(os.path.join(checkpoint_dir, \"ckpt-200000\")).expect_partial()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b9a5f37c-098b-4f21-9ce7-12387c2bb63c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing from scratch.\n"
     ]
    }
   ],
   "source": [
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_dir, max_to_keep=3)\n",
    "\n",
    "\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "    print(f\"Restoring from {ckpt_manager.latest_checkpoint}\")\n",
    "    ckpt.restore(ckpt_manager.latest_checkpoint).expect_partial()\n",
    "else:\n",
    "    print(\"Initializing from scratch.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4cd7b5f9-792f-4052-914c-08e5cd33d4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "AMINO_ACIDS = \"ACDEFGHIKLMNPQRSTVWY\"  # 20 residues\n",
    "AA_TO_IDX = {aa: i + 1 for i, aa in enumerate(AMINO_ACIDS)}\n",
    "PAD_IDX = 0\n",
    "VOCAB_SIZE = 21  # 0 (PAD) + 1–20\n",
    "\n",
    "MAX_LEN = 160\n",
    "\n",
    "def decode_sequence(onehot):\n",
    "    tokens = tf.argmax(onehot, axis=-1).numpy().flatten()\n",
    "    return ''.join([AMINO_ACIDS[i - 1] if i != 0 else '-' for i in tokens])\n",
    "\n",
    "def decode_batch(batch_tensor: tf.Tensor) -> list[str]:\n",
    "    \"\"\"\n",
    "    Decodes a batch of one-hot encoded tensors into amino acid sequences.\n",
    "\n",
    "    Supports input of shape:\n",
    "        - (B, 1, L, 21)\n",
    "        - (B, L, 21)\n",
    "\n",
    "    Returns:\n",
    "        List of decoded strings of length B\n",
    "    \"\"\"\n",
    "    if batch_tensor.shape.rank == 4:\n",
    "        batch_tensor = tf.squeeze(batch_tensor, axis=1)  # (B, L, 21)\n",
    "\n",
    "    return [decode_sequence(seq) for seq in batch_tensor]\n",
    "\n",
    "\n",
    "def encode_sequence(seq):\n",
    "    \"\"\"\n",
    "    Encode a sequence into one-hot with shape [1, MAX_LEN, 21]\n",
    "    \"\"\"\n",
    "    seq = seq.upper()\n",
    "    indices = [AA_TO_IDX.get(aa, PAD_IDX) for aa in seq[:MAX_LEN]]\n",
    "    if len(indices) < MAX_LEN:\n",
    "        indices += [PAD_IDX] * (MAX_LEN - len(indices))\n",
    "    one_hot = tf.one_hot(indices, depth=VOCAB_SIZE, dtype=tf.float32)  # [MAX_LEN, 21]\n",
    "    return tf.expand_dims(one_hot, axis=0)  # [1, MAX_LEN, 21]\n",
    "\n",
    "def encode_batch(sequences):\n",
    "    \"\"\"\n",
    "    Encode a batch of sequences -> [B, 1, MAX_LEN, 21]\n",
    "    \"\"\"\n",
    "    encoded = [encode_sequence(seq) for seq in sequences]\n",
    "    return tf.stack(encoded, axis=0)  # [B, 1, MAX_LEN, 21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1a55a1e3-4770-40bf-a81c-8641cbc1e623",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_aa_distribution(batch):\n",
    "    \"\"\"\n",
    "    Compute normalized amino acid distribution from a one-hot batch,\n",
    "    excluding padding (index 0). Supports shape (B, 1, L, 21) or (B, L, 21).\n",
    "    \"\"\"\n",
    "    if batch.shape.rank == 4:\n",
    "        batch = tf.squeeze(batch, axis=1)  # → (B, L, 21)\n",
    "\n",
    "    batch = tf.cast(batch, tf.float32)\n",
    "    # Exclude padding channel (index 0)\n",
    "    batch = batch[..., 1:]  # → shape: (B, L, 20)\n",
    "\n",
    "    counts = tf.reduce_sum(batch, axis=[0, 1])  # → (20,)\n",
    "    total = tf.reduce_sum(counts)\n",
    "    prob = tf.where(total > 0, counts / total, tf.zeros_like(counts))\n",
    "    return prob.numpy()\n",
    "\n",
    "def js_divergence_per_position(real_batch, gen_batch):\n",
    "    \"\"\"\n",
    "    Computes JS divergence for each position along the sequence (excluding padding index).\n",
    "    Supports input shape (B, 1, L, 21) or (B, L, 21).\n",
    "    Returns: np.array of shape (L,) — JS divergence per position\n",
    "    \"\"\"\n",
    "    if real_batch.shape.rank == 4:\n",
    "        real_batch = tf.squeeze(real_batch, axis=1)\n",
    "    if gen_batch.shape.rank == 4:\n",
    "        gen_batch = tf.squeeze(gen_batch, axis=1)\n",
    "\n",
    "    real_batch = tf.cast(real_batch, tf.float32).numpy()\n",
    "    gen_batch = tf.cast(gen_batch, tf.float32).numpy()\n",
    "\n",
    "    L = real_batch.shape[1]\n",
    "    jsd_pos = []\n",
    "\n",
    "    for i in range(L):\n",
    "        p_real = np.mean(real_batch[:, i, 1:], axis=0)  # exclude padding (index 0)\n",
    "        p_gen = np.mean(gen_batch[:, i, 1:], axis=0)\n",
    "        p_real /= np.sum(p_real) + 1e-8\n",
    "        p_gen /= np.sum(p_gen) + 1e-8\n",
    "        jsd = jensenshannon(p_real, p_gen, base=2)\n",
    "        jsd_pos.append(jsd)\n",
    "    \n",
    "    return np.array(jsd_pos)\n",
    "\n",
    "def sequence_lengths(onehot_batch):\n",
    "    indices = tf.argmax(onehot_batch, axis=-1)\n",
    "    non_padding = tf.not_equal(indices, 0)\n",
    "    return tf.reduce_sum(tf.cast(non_padding, tf.int32), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8a37eb7c-d89d-4304-b1ce-ba13017cbe70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalized_hamming_distance(seq1, seq2):\n",
    "    \"\"\"Compute normalized Hamming distance between two equal-length strings.\"\"\"\n",
    "    assert len(seq1) == len(seq2), \"Sequences must be the same length\"\n",
    "    return sum(a != b for a, b in zip(seq1, seq2)) / len(seq1)\n",
    "\n",
    "def filter_diverse_sequences(sequences, threshold=0.05, max_count=None):\n",
    "    diverse = []\n",
    "    for seq in sequences:\n",
    "        if all(normalized_hamming_distance(seq, d) >= threshold for d in diverse):\n",
    "            diverse.append(seq)\n",
    "        if max_count is not None and len(diverse) >= max_count:\n",
    "            break\n",
    "    return diverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d7ce38a1-383e-4f18-a76d-f00526421cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally pass amino acid sequence if you want labels\n",
    "def save_attention_png(attn, filename=\"attn_map.png\", aa_seq=None):\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    plt.imshow(attn, cmap='viridis')\n",
    "    plt.title(\"Attention Heatmap\")\n",
    "    if aa_seq:\n",
    "        plt.xticks(ticks=range(len(aa_seq)), labels=list(aa_seq), fontsize=6, rotation=90)\n",
    "        plt.yticks(ticks=range(len(aa_seq)), labels=list(aa_seq), fontsize=6)\n",
    "    else:\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filename)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "02600cd7-8e4b-4e06-be87-b959ac54b7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_attention_to_disk(attn_scores, sequences, step, output_dir=\"attn_logs\"):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    for i in range(attn_scores.shape[0]):\n",
    "        sample_path = os.path.join(output_dir, f\"sample_{i}_step_{step}.npz\")\n",
    "        np.savez_compressed(sample_path,\n",
    "                            attn=attn_scores[i].numpy(),  # shape [H, W, W]\n",
    "                            sequence=sequences[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "59b88631-e295-4874-b7f4-431081850047",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_attention_to_tensorboard(attn_scores, sequences, step, summary_writer):\n",
    "    \"\"\"\n",
    "    attn_scores: Tensor [B, H, W, W]\n",
    "    sequences: list of strings\n",
    "    \"\"\"\n",
    "    B, H, W, _ = attn_scores.shape\n",
    "    attn_scores = attn_scores.numpy()  # Convert for plotting\n",
    "    with summary_writer.as_default():\n",
    "        for i in range(min(B, 2)):  # log up to 2 samples\n",
    "            for h in range(H):\n",
    "                fig, ax = plt.subplots(figsize=(6, 6), dpi=100)\n",
    "                attn = attn_scores[i, h]  # [W, W]\n",
    "                im = ax.imshow(attn, cmap='magma', vmin=0.0, vmax=1.0)\n",
    "\n",
    "                ax.set_title(f\"Sample {i}, Head {h}\")\n",
    "                ax.set_xlabel(\"Residue Index\")\n",
    "                ax.set_ylabel(\"Residue Index\")\n",
    "\n",
    "                # Show ticks every 20 residues for readability\n",
    "                tick_positions = np.arange(0, W, 20)\n",
    "                ax.set_xticks(tick_positions)\n",
    "                ax.set_yticks(tick_positions)\n",
    "\n",
    "                # Optional: sequence length overlay\n",
    "                seq_len = len(sequences[i].replace(\"-\", \"\"))\n",
    "                ax.axvline(seq_len, color='white', linestyle='--', linewidth=1)\n",
    "                ax.axhline(seq_len, color='white', linestyle='--', linewidth=1)\n",
    "\n",
    "                plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "                plt.tight_layout()\n",
    "\n",
    "                # Save to TensorBoard\n",
    "                buf = io.BytesIO()\n",
    "                plt.savefig(buf, format='png')\n",
    "                plt.close(fig)\n",
    "                buf.seek(0)\n",
    "\n",
    "                image = tf.image.decode_png(buf.getvalue(), channels=4)\n",
    "                image = tf.expand_dims(image, 0)\n",
    "                tf.summary.image(f\"AttentionMaps/Sample{i}_Head{h}\", image, step=step)\n",
    "\n",
    "            tf.summary.text(f\"Attention/Sequence_{i}\", tf.convert_to_tensor([sequences[i]]), step=step)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f7c89612-ede3-462c-b597-53d4f818dc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_embeddings_with_tsne_umap(real_sequences, generator, discriminator, z_dim, encode_batch_fn, step):\n",
    "    \"\"\"\n",
    "    Logs both t-SNE and UMAP plots comparing real and generated embeddings using discriminator.\n",
    "    Returns two image tensors (t-SNE, UMAP) and cosine similarity.\n",
    "    \"\"\"\n",
    "    # Encode real sequences\n",
    "    x_real = encode_batch_fn(real_sequences)\n",
    "    real_embed = discriminator(x_real, return_embedding=True)\n",
    "\n",
    "    # Generate fake sequences\n",
    "    z = tf.random.normal([len(real_sequences), z_dim])\n",
    "    x_fake = generator(z, training=False, return_hard=True)\n",
    "    fake_embed = discriminator(x_fake, return_embedding=True)\n",
    "\n",
    "    # Cosine similarity\n",
    "    cos_sim = -tf.reduce_mean(tf.keras.losses.cosine_similarity(real_embed, fake_embed, axis=-1))\n",
    "\n",
    "    # Prepare for embedding\n",
    "    X = tf.concat([real_embed, fake_embed], axis=0).numpy()\n",
    "    y = np.array([0] * len(real_sequences) + [1] * len(real_sequences))\n",
    "\n",
    "    # --- t-SNE ---\n",
    "    tsne = TSNE(n_components=2, perplexity=30, init='pca', random_state=42)\n",
    "    tsne_X = tsne.fit_transform(X)\n",
    "\n",
    "    # --- UMAP ---\n",
    "    reducer = umap.UMAP(n_components=2, random_state=42)\n",
    "    umap_X = reducer.fit_transform(X)\n",
    "\n",
    "    # --- t-SNE Plot ---\n",
    "    tsne_buf = io.BytesIO()\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.scatter(tsne_X[y == 0, 0], tsne_X[y == 0, 1], label=\"Real\", alpha=0.6, s=12)\n",
    "    plt.scatter(tsne_X[y == 1, 0], tsne_X[y == 1, 1], label=\"Generated\", alpha=0.6, s=12)\n",
    "    plt.title(f\"t-SNE at step {step}\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(tsne_buf, format='png')\n",
    "    plt.close()\n",
    "    tsne_buf.seek(0)\n",
    "\n",
    "    tsne_img = tf.image.decode_png(tsne_buf.getvalue(), channels=4)\n",
    "    tsne_img = tf.expand_dims(tsne_img, 0)\n",
    "\n",
    "    # --- UMAP Plot ---\n",
    "    umap_buf = io.BytesIO()\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.scatter(umap_X[y == 0, 0], umap_X[y == 0, 1], label=\"Real\", alpha=0.6, s=12)\n",
    "    plt.scatter(umap_X[y == 1, 0], umap_X[y == 1, 1], label=\"Generated\", alpha=0.6, s=12)\n",
    "    plt.title(f\"UMAP at step {step}\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(umap_buf, format='png')\n",
    "    plt.close()\n",
    "    umap_buf.seek(0)\n",
    "\n",
    "    umap_img = tf.image.decode_png(umap_buf.getvalue(), channels=4)\n",
    "    umap_img = tf.expand_dims(umap_img, 0)\n",
    "\n",
    "    return tsne_img, umap_img, cos_sim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cd861ca5-27dd-4508-ab4f-2e787458b14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "real_df = pd.read_csv(\"/home1/zzhang201@kgi.edu/GAN/zzGAN/gan/data/zz/sample_seqs.csv\")\n",
    "real_seqs = real_df[\"sequence\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb17ccca-5aea-4872-b17b-a242dae2f9fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11999] Generator Loss: -5.4409, Discriminator Loss: -1.3458\n",
      "Custom scalar layout written to /home1/zzhang201@kgi.edu/GAN/zzGAN/logs/zz/multiG_attn_adjusted_embed/plugins/custom_scalar/custom_scalars_layout.json\n",
      "Sample 0:\n",
      "QGQYVEGYGGSTTISVEGFGVEGYGGSTTIRVEGFGVEQYGGSTTIRVEGFGLEQAGGSTTIRVEGFGLEQGGGSTTIRVEGFGLEQAGGSTTIRVEGFGLEQAGGSTTIRVEGFGVEQGGGSTTIRVEGFGLEQA-----------------------V\n",
      "\n",
      "Sample 1:\n",
      "QGQYVEGVGGSTTIRVEGFGVEQGGGSTTIRVEGFGVEQGGGSTTIRVEGKGLEQAGGSTTIRVEGKGLEQAGGSTTIRVEGFGVEQGGGSTTIRVEGFGLEQA-----------------------VEGFGLEQG-----------------------V\n",
      "\n",
      "Sample 2:\n",
      "QGQYVEGVGGSTTISVEGKGLEQRGGSTTIRVEGKGLEQAGGSTTIR-----------STTI-VEGFGVEQAGGSTTIRVEGFGVEGGGGSTTIRVEGFGLEQG-----------------------VEGFGLEQG-----------------------V\n",
      "\n",
      "Sample 3:\n",
      "QGQYVEGYGGSTTISVEGFGVEQAGGSTTIRVEGFGVEQGGGSTTISVEGFGVEGGGGSTTISVEGFGLEGAGGSTTIRVEGFGLEQGGGSTTIRVEGFGLEQGGGSTTIRVEGKGLEQAGGSTTIRVEGFGLEQGG----------------------V\n",
      "Limiting hmmer search to species ['human', 'mouse'] was requested but hits did not achieve a high enough bitscore. Reverting to using any species\n",
      "Limiting hmmer search to species ['human', 'mouse'] was requested but hits did not achieve a high enough bitscore. Reverting to using any species\n",
      "Limiting hmmer search to species ['human', 'mouse'] was requested but hits did not achieve a high enough bitscore. Reverting to using any species\n",
      "Limiting hmmer search to species ['human', 'mouse'] was requested but hits did not achieve a high enough bitscore. Reverting to using any species\n",
      "Limiting hmmer search to species ['human', 'mouse'] was requested but hits did not achieve a high enough bitscore. Reverting to using any species\n",
      "Limiting hmmer search to species ['human', 'mouse'] was requested but hits did not achieve a high enough bitscore. Reverting to using any species\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home1/zzhang201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/site-packages/scipy/spatial/distance.py:1261: RuntimeWarning: invalid value encountered in divide\n",
      "  p = p / np.sum(p, axis=axis, keepdims=True)\n",
      "/home1/zzhang201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/site-packages/scipy/spatial/distance.py:1262: RuntimeWarning: invalid value encountered in divide\n",
      "  q = q / np.sum(q, axis=axis, keepdims=True)\n"
     ]
    }
   ],
   "source": [
    "from tensorboard.plugins.hparams import api as hp\n",
    "from IPython.display import clear_output\n",
    "from gan.protein.hyperparameter import create_hparam_config\n",
    "from gan.protein.custom_scalars import generate_dynamic_layout\n",
    "\"\"\"\n",
    "create_hparam_config(config_dir)\n",
    "HP_BATCH_SIZE = hp.HParam('batch_size', hp.Discrete([32]))\n",
    "HP_Z_DIM = hp.HParam('z_dim', hp.Discrete([128]))\n",
    "HP_GF_DIM = hp.HParam('gf_dim', hp.Discrete([64]))\n",
    "HP_DF_DIM = hp.HParam('df_dim', hp.Discrete([64]))\n",
    "HP_G_LR = hp.HParam('generator_lr', hp.Discrete([1e-3, 5e-4]))\n",
    "HP_D_LR = hp.HParam('discriminator_lr', hp.Discrete([1e-3, 5e-4]))\n",
    "HP_C_CYCLE = hp.HParam('critic_cycle', hp.Discrete([1,2,3,4,5]))\n",
    "HP_C_CYCLE_SCH = hp.HParam('critic_cycle_schedule', hp.Discrete([20000]))\n",
    "HP_ATTN_POS = hp.HParam('attention_head_position', hp.Discrete([2, 3]))\n",
    "# Log current run's HParams\n",
    "hparams = {\n",
    "    HP_BATCH_SIZE: FLAGS.batch_size,\n",
    "    HP_Z_DIM: FLAGS.z_dim,\n",
    "    HP_GF_DIM: FLAGS.gf_dim,\n",
    "    HP_DF_DIM: FLAGS.df_dim,\n",
    "    HP_G_LR: FLAGS.generator_learning_rate,\n",
    "    HP_D_LR: FLAGS.discriminator_learning_rate,\n",
    "    HP_C_CYCLE: FLAGS.d_step,\n",
    "    HP_C_CYCLE_SCH: FLAGS.multid_schedule,\n",
    "    HP_ATTN_POS: FLAGS.attn_pos\n",
    "}\n",
    "\n",
    "with summary_writer.as_default():\n",
    "    hp.hparams(hparams)\n",
    "\"\"\"\n",
    "real_iter = iter(dataset)\n",
    "# === Training Loop ===\n",
    "for step in range(FLAGS.steps):\n",
    "    if step < FLAGS.multid_schedule:\n",
    "        d_step = 1\n",
    "    else:\n",
    "        d_step = FLAGS.d_step\n",
    "    for _ in range(d_step):\n",
    "        real_batch = next(real_iter)\n",
    "        d_loss, d_grad_norm = train_discriminator_step(\n",
    "            model.g_model, model.d_model,\n",
    "            model.d_optim, real_batch, FLAGS.z_dim\n",
    "        )\n",
    "\n",
    "    g_loss, g_grad_norm = train_generator_step(\n",
    "        model.g_model, model.d_model,\n",
    "        model.g_optim, FLAGS.z_dim\n",
    "    )\n",
    "    model.g_model.global_step.assign_add(1)\n",
    "\n",
    "    # === Scalar summaries ===\n",
    "    if (step + 1) % FLAGS.save_summary_steps == 0 or step == FLAGS.steps - 1:\n",
    "        clear_output(wait=True)\n",
    "        print(f\"[{step}] Generator Loss: {g_loss:.4f}, Discriminator Loss: {d_loss:.4f}\")\n",
    "        with summary_writer.as_default():\n",
    "            tf.summary.scalar(\"Generator_Loss\", g_loss, step=step)\n",
    "            tf.summary.scalar(\"Discriminator_Loss\", d_loss, step=step)\n",
    "            tf.summary.scalar(\"Gradients/Generator\", g_grad_norm, step=step)\n",
    "            tf.summary.scalar(\"Gradients/Discriminator\", d_grad_norm, step=step)\n",
    "\n",
    "        summary_writer.flush()\n",
    "        generate_dynamic_layout(logdir=os.path.join(FLAGS.logdir, FLAGS.name), run_name=timestamp)\n",
    "\n",
    "    # === Generated sequence preview ===\n",
    "    if (step + 1) % 1000 == 0 or step == FLAGS.steps - 1:\n",
    "        z = tf.random.normal([8, FLAGS.z_dim])\n",
    "        samples = model.g_model(z, training=False, return_hard=True, return_attention=True)\n",
    "        samples = tf.squeeze(samples, axis=1)\n",
    "        sequences = [decode_sequence(seq) for seq in samples]\n",
    "        append_generated_sequences(step=step, sequences=sequences)\n",
    "        \n",
    "        attn_scores = model.g_model.last_attn_scores\n",
    "        save_attention_to_disk(attn_scores, sequences, step, output_dir=attn_dir)\n",
    "        tf.print(\"\\n\".join(f\"Sample {i}: {sequences[i][:50]}...\" for i in range(len(sequences))))\n",
    "\n",
    "    if (step + 1) % 500 == 0 or step == FLAGS.steps - 1:\n",
    "        z = tf.random.normal([64, FLAGS.z_dim])\n",
    "        hard_batch = model.g_model(z, training=False, return_hard=True)\n",
    "        real_batch = next(real_iter)\n",
    "        gen_seqs = decode_batch(hard_batch)\n",
    "        real_seqs = decode_batch(real_batch)\n",
    "        fr_loss, cdr_loss = quality_losses(gen_seqs, real_seqs, full_real_frs_csv=\"data/vh_regions.csv\")\n",
    "        anarci_stats = anarci_quality_log(gen_seqs)\n",
    "        \n",
    "        p_gen = get_aa_distribution(hard_batch)\n",
    "        p_real = get_aa_distribution(real_batch)\n",
    "        jsd = jensenshannon(p_real, p_gen, base=2)\n",
    "    \n",
    "        real_lengths = sequence_lengths(real_batch)\n",
    "        gen_lengths = sequence_lengths(hard_batch)\n",
    "    \n",
    "        # === Per-position JS divergence\n",
    "        jsd_pos = js_divergence_per_position(real_batch, hard_batch)\n",
    "        valid_jsd = jsd_pos[~np.isnan(jsd_pos)]\n",
    "        length_diff = tf.reduce_mean(tf.cast(gen_lengths, tf.float32)) - tf.reduce_mean(tf.cast(real_lengths, tf.float32))\n",
    "        with summary_writer.as_default():\n",
    "            tf.summary.scalar(\"JS_Divergence/Aggregated\", jsd, step=step)\n",
    "            tf.summary.histogram(\"JS_Divergence/Per_Position\", jsd_pos, step=step)\n",
    "            tf.summary.scalar(\"JS_Divergence/Per_Position_Mean\", np.mean(valid_jsd), step=step)\n",
    "            tf.summary.scalar(\"JS_Divergence/Per_Position_Max\", np.max(valid_jsd), step=step)\n",
    "            tf.summary.scalar(\"JS_Divergence/Per_Position_Std\", np.std(valid_jsd), step=step)\n",
    "            \n",
    "            tf.summary.scalar(\"Length/Real_mean\", tf.reduce_mean(real_lengths), step=step)\n",
    "            tf.summary.scalar(\"Length/Generated_mean\", tf.reduce_mean(gen_lengths), step=step)\n",
    "            tf.summary.scalar(\"Length/Generated_stddev\", tf.math.reduce_std(tf.cast(gen_lengths, tf.float32)), step=step)\n",
    "            tf.summary.scalar(\"Length/Diff_Gen_minus_Real\", length_diff, step=step)\n",
    "\n",
    "            tf.summary.scalar(\"Anarci/FR_Loss\", fr_loss, step=step)\n",
    "            tf.summary.scalar(\"Anarci/CDR_JS_Loss\", cdr_loss, step=step)\n",
    "            tf.summary.scalar(\"Anarci/AnyHit\", anarci_stats[\"full_hit\"] + anarci_stats[\"partial_hit\"], step=step)\n",
    "            tf.summary.scalar(\"Anarci/FullHit\", anarci_stats[\"full_hit\"], step=step)\n",
    "            tf.summary.scalar(\"Anarci/PartialHit\", anarci_stats[\"partial_hit\"], step=step)\n",
    "            tf.summary.scalar(\"Anarci/NoHit\", anarci_stats[\"no_hit\"], step=step)\n",
    "\n",
    "\n",
    "    # === Checkpointing ===\n",
    "    if (step + 1) % FLAGS.save_checkpoint_sec == 0 or step == FLAGS.steps - 1:\n",
    "        ckpt_manager.save()\n",
    "        print(f\"Checkpoint saved at step {step}\")\n",
    "\n",
    "    if (step + 1) % 2500 == 0 or step == FLAGS.steps - 1:\n",
    "        tsne_img, umap_img, cos_sim = log_embeddings_with_tsne_umap(\n",
    "            real_sequences=real_seqs,\n",
    "            generator=model.g_model,\n",
    "            discriminator=model.d_model,\n",
    "            z_dim=FLAGS.z_dim,\n",
    "            encode_batch_fn=encode_batch,\n",
    "            step=step\n",
    "        )\n",
    "        \n",
    "        with summary_writer.as_default():\n",
    "            tf.summary.image(\"t-SNE/Real_vs_Generated\", tsne_img, step=step)\n",
    "            tf.summary.image(\"UMAP/Real_vs_Generated\", umap_img, step=step)\n",
    "            tf.summary.scalar(\"Cosine_Similarity/Real_vs_Generated\", cos_sim, step=step)\n",
    "\n",
    "        \n",
    "    if step == FLAGS.steps - 1:\n",
    "        z = tf.random.normal([300, FLAGS.z_dim])\n",
    "        hard_batch = model.g_model(z, training=False, return_hard=True, return_attention=True)\n",
    "        hard_batch = tf.squeeze(hard_batch, axis=1)\n",
    "        sequences = [decode_sequence(seq) for seq in hard_batch]\n",
    "    \n",
    "        # Collect as many diverse sequences as possible (no cap)\n",
    "        diverse_seqs = filter_diverse_sequences(sequences, threshold=0.05, max_count=None)\n",
    "        # Loop over heads and samples\n",
    "        for i in range(4):\n",
    "            for h in range(2):\n",
    "                attn = model.g_model.last_attn_scores[i, h]  # shape [160, 160]\n",
    "                save_attention_png(\n",
    "                    attn.numpy(),\n",
    "                    filename=f\"attn_sample{i}_head{h}.png\",\n",
    "                    aa_seq=sequences[i]\n",
    "                )\n",
    "    \n",
    "        with summary_writer.as_default():\n",
    "            for i, seq in enumerate(diverse_seqs[:30]):  # log only first 30\n",
    "                tf.summary.text(f\"Final/DiverseSequence_{i}\", tf.convert_to_tensor([seq]), step=step)\n",
    "            tf.summary.scalar(\"Final/NumDiverseSequences\", len(diverse_seqs), step=step)\n",
    "    \n",
    "        print(f\"Generated {len(sequences)} sequences.\")\n",
    "        print(f\"Found {len(diverse_seqs)} diverse sequences.\")\n",
    "        print(f\"Logged first {min(30, len(diverse_seqs))} to TensorBoard.\")\n",
    "        summary_writer.flush()\n",
    "        generate_dynamic_layout(logdir=os.path.join(FLAGS.logdir, FLAGS.name), run_name=timestamp)\n",
    "        print(f\"Layout updated based on {log_dir}\")\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc58ce1-beb9-479a-8ea4-71540d253caf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "tf2_16",
   "language": "python",
   "name": "tf2_16"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
