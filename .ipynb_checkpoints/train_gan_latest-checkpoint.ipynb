{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bf76c30-4cfb-42d2-ab59-8ff96dfb74e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "815d6199-17b2-4e8f-aede-60ae3c35d4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home1/zzhang201@kgi.edu/GAN/zzGAN/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29b016c6-6cd8-4b00-b56d-268d1abbd146",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-19 21:58:04.624381: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-19 21:58:04.656423: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# import tensorflow_gan as tfgan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c01e5ef2-45e5-4008-a99a-c108ba64dfa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF version: 2.16.1\n",
      "GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "print(\"TF version:\", tf.__version__)\n",
    "print(\"GPUs:\", tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f7a9d9f-d845-44f6-83e2-6bfb7996d386",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import jensenshannon\n",
    "import matplotlib.ticker as ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c767d0e-858f-4169-9d34-6951dbe77a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home1/zzhang201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import umap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33435abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import random\n",
    "import datetime\n",
    "import platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6785f0f-c59d-4899-b738-2ee049d2ecf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import gan.documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2052766",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gan.models import get_model, get_specific_hooks\n",
    "from gan.parameters import get_flags\n",
    "from gan.documentation import setup_logdir, get_properties\n",
    "from gan.documentation import print_run_meta_data, add_model_metadata\n",
    "from tensorflow.keras import mixed_precision\n",
    "from tensorflow.keras.mixed_precision import LossScaleOptimizer\n",
    "# Enable global mixed precision policy\n",
    "mixed_precision.set_global_policy('mixed_float16')\n",
    "from protein.quality_gates import quality_losses, anarci_quality_log\n",
    "from protein.custom_scalars import generate_dynamic_layout\n",
    "from gan.protein.esm_utils import esm_mse_loss, esm_cosine_loss, esm_embed, esm_fid, esm_umap_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0040c371-8a1c-4349-a3f1-b8bcc2b2ec73",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FakeFlags:\n",
    "    # General model setup\n",
    "    model_type = 'wgan'\n",
    "    architecture = 'gumbel'\n",
    "    batch_size = 64\n",
    "    z_dim = 128\n",
    "    gf_dim = 64\n",
    "    df_dim = 64\n",
    "    dim = gf_dim\n",
    "    attn_pos = 2\n",
    "\n",
    "    # Kernel and dilation config\n",
    "    kernel_height = 3\n",
    "    kernel_width = 3\n",
    "    dilation_rate = 2\n",
    "    pooling = 'conv'\n",
    "\n",
    "    # Optional: logging / save frequency\n",
    "    name = 'trial2'\n",
    "    steps = 20000\n",
    "    save_summary_steps = 1000\n",
    "    save_checkpoint_sec = 5000\n",
    "\n",
    "    # Optimizer settings\n",
    "    generator_learning_rate = 1e-4\n",
    "    discriminator_learning_rate = 1e-4\n",
    "    beta1 = 0.5\n",
    "    beta2 = 0.9\n",
    "\n",
    "    # Dataset & file structure\n",
    "    dataset = 'zz'\n",
    "    seq_length = 160\n",
    "    logdir = '/project/animesh_ray_1465/Zihao/GAN/logs'\n",
    "    # properties_file = 'properties.json'\n",
    "\n",
    "    # Misc\n",
    "    seed = 970713\n",
    "    resume_from = None\n",
    "    # finetune_from = '/home1/zzhang201@kgi.edu/GAN/zzGAN/logs/zz/multiG_attn_adjusted_embed/20250724-032823/'\n",
    "    multid_schedule = 20000\n",
    "    d_step = 3\n",
    "    shuffle_buffer_size = 1000\n",
    "    label_noise_level = 0.0\n",
    "    noise_level = 0.0\n",
    "\n",
    "    # ESM flags\n",
    "    esm_loss_weight = 0.05   # Start here; try 0.01–0.2\n",
    "    esm_model = \"esm2_t6_8M_UR50D\"   # Easy switching\n",
    "    esm_batch = 64\n",
    "    esm_device = \"cuda\"   # Change to \"cuda\" if you have GPU free\n",
    "    esm_loss_type = \"mse\"  # or \"cosine\"\n",
    "\n",
    "    def flag_values_dict(self):\n",
    "        return {k: getattr(self, k) for k in dir(self)\n",
    "                if not k.startswith(\"__\") and not callable(getattr(self, k))}\n",
    "FLAGS = FakeFlags()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "339bfacc-054f-48b8-b491-c4bbc50bb11c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-19 21:58:16.971153: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43622 MB memory:  -> device: 0, name: NVIDIA L40S, pci bus id: 0000:21:00.0, compute capability: 8.9\n",
      "2025-11-19 21:58:16.971742: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 43622 MB memory:  -> device: 1, name: NVIDIA L40S, pci bus id: 0000:e1:00.0, compute capability: 8.9\n"
     ]
    }
   ],
   "source": [
    "random.seed(FLAGS.seed)\n",
    "np.random.seed(FLAGS.seed)\n",
    "tf.random.set_seed(FLAGS.seed)\n",
    "# Fixed latent for eval snapshots so runs are comparable\n",
    "Z_EVAL = tf.random.stateless_normal([128, FLAGS.z_dim], seed=(970, 713))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "defe8e17-ad68-48a9-9124-8c8968a7b581",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_flags(flags, log_dir, filename=\"flags.json\"):\n",
    "    \"\"\"Save FLAGS to a JSON file in the log directory.\"\"\"\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "    file_path = os.path.join(log_dir, filename)\n",
    "\n",
    "    with open(file_path, \"w\") as f:\n",
    "        json.dump(flags.flag_values_dict(), f, indent=4)\n",
    "    \n",
    "    print(f\"[FLAGS] Saved flags to {file_path}\")\n",
    "\n",
    "def load_flags(log_dir, filename=\"flags.json\"):\n",
    "    \"\"\"Load FLAGS from JSON file and return as a FakeFlags object.\"\"\"\n",
    "    file_path = os.path.join(log_dir, filename)\n",
    "\n",
    "    if not os.path.exists(file_path):\n",
    "        raise FileNotFoundError(f\"[FLAGS] No flags file found at {file_path}\")\n",
    "\n",
    "    with open(file_path, \"r\") as f:\n",
    "        flag_dict = json.load(f)\n",
    "\n",
    "    # Create a new FakeFlags object and set attributes\n",
    "    loaded_flags = FakeFlags()\n",
    "    for k, v in flag_dict.items():\n",
    "        setattr(loaded_flags, k, v)\n",
    "\n",
    "    print(f\"[FLAGS] Loaded flags from {file_path}\")\n",
    "    return loaded_flags\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "01d532a0-2ebb-4502-8e0b-51d512fd2b30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home1/zzhang201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/site-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
      "  warnings.warn(\n",
      "2025-11-19 21:58:17.304954: E tensorflow/core/util/util.cc:131] oneDNN supports DT_HALF only on platforms with AVX-512. Falling back to the default Eigen-based implementation if present.\n",
      "2025-11-19 21:58:18.118253: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing from scratch.\n",
      "[FLAGS] Saved flags to /project/animesh_ray_1465/Zihao/GAN/logs/trial2/20251119-215817/summaries/flags.json\n"
     ]
    }
   ],
   "source": [
    "import os, json, datetime, tensorflow as tf\n",
    "from protein.ema import EMA\n",
    "# 0) Make run dirs first (RUN_DIR, CKPT_DIR, SUMM_DIR, ATTN_DIR, etc.)\n",
    "timestamp   = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "RUN_DIR     = os.path.join(FLAGS.logdir, FLAGS.name, timestamp)\n",
    "CKPT_DIR    = os.path.join(RUN_DIR, \"checkpoints\")\n",
    "SUMM_DIR    = os.path.join(RUN_DIR, \"summaries\")\n",
    "ATTN_DIR    = os.path.join(RUN_DIR, \"attn_scores\")\n",
    "GENS_DIR    = os.path.join(RUN_DIR, \"generated\")\n",
    "\n",
    "for d in (CKPT_DIR, SUMM_DIR, ATTN_DIR, GENS_DIR):\n",
    "    os.makedirs(d, exist_ok=True)\n",
    "\n",
    "# 1) Build models/opts (objects only; no variables yet)\n",
    "noise = tf.random.normal([FLAGS.batch_size, FLAGS.z_dim], dtype=tf.float32)\n",
    "model = get_model(FLAGS, RUN_DIR, noise)\n",
    "g_model, d_model = model.g_model, model.d_model\n",
    "g_opt, d_opt     = model.g_optim, model.d_optim\n",
    "\n",
    "# 2) Global step (int32 to match old ckpts) and attach to G\n",
    "global_step = tf.Variable(0, dtype=tf.int32, name=\"global_step\")\n",
    "setattr(g_model, \"global_step\", global_step)\n",
    "\n",
    "# 3) WARM-UP once in fp32 to create ALL variables eagerly (prevents trace/deferred issues)\n",
    "_ = g_model(tf.random.normal([1, FLAGS.z_dim], dtype=tf.float32), training=False, return_hard=False)\n",
    "SEQ_LEN = getattr(FLAGS, \"seq_len\", 160)\n",
    "VOCAB   = getattr(FLAGS, \"vocab_size\", 21)\n",
    "_ = d_model(tf.random.normal([1, 1, SEQ_LEN, VOCAB], dtype=tf.float32), training=False)\n",
    "\n",
    "# 4) Create EMA object and **build it now** (so shadows exist for restore)\n",
    "ema = EMA(decay=getattr(FLAGS, \"ema_decay\", 0.999))\n",
    "ema.build(g_model)   # shadows initialized from current g_model weights (fp32)\n",
    "\n",
    "# 5) Create a checkpoint that includes models, optimizers, step, and EMA\n",
    "# We now explicitly pass the generator's list of variables\n",
    "ckpt = tf.train.Checkpoint(\n",
    "    generator_variables=g_model.variables,  # The FIX: Pass the variable list directly\n",
    "    discriminator=d_model,\n",
    "    g_optimizer=g_opt,\n",
    "    d_optimizer=d_opt,\n",
    "    step=global_step,\n",
    "    ema=ema\n",
    ")\n",
    "\n",
    "# 6) Restore (if any). Use a *temporary manager* pointed at the SOURCE dir.\n",
    "RESUME_FROM   = getattr(FLAGS, \"resume_from\", None)\n",
    "FINETUNE_FROM = getattr(FLAGS, \"finetune_from\", None)\n",
    "\n",
    "def _restore_from(src_dir, label):\n",
    "    src_mgr = tf.train.CheckpointManager(ckpt, os.path.join(src_dir, \"checkpoints\"), max_to_keep=5)\n",
    "    if not src_mgr.latest_checkpoint:\n",
    "        raise FileNotFoundError(f\"No checkpoint found in {src_dir}/checkpoints\")\n",
    "    status = ckpt.restore(src_mgr.latest_checkpoint)\n",
    "    status.expect_partial()  # OK: SN u-vectors & (possibly) EMA may differ\n",
    "    print(f\"[{label}] restored:\", src_mgr.latest_checkpoint)\n",
    "\n",
    "if RESUME_FROM:\n",
    "    _restore_from(RESUME_FROM, \"RESUME\")      # same run, same objective → restores opts + EMA if present\n",
    "elif FINETUNE_FROM:\n",
    "    _restore_from(FINETUNE_FROM, \"FINETUNE\")  # see weights-only variant below if you don't want optimizer state\n",
    "else:\n",
    "    print(\"Initializing from scratch.\")\n",
    "\n",
    "# 7) Destination manager for THIS run (saves to your new RUN_DIR)\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, CKPT_DIR, max_to_keep=5)\n",
    "\n",
    "# 8) Summary writer\n",
    "summary_writer = tf.summary.create_file_writer(SUMM_DIR)\n",
    "\n",
    "# 9) Save flags, expose paths\n",
    "save_flags(FLAGS, SUMM_DIR)\n",
    "attn_dir = ATTN_DIR\n",
    "log_dir  = RUN_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "25eb59dd-b1e0-4313-a26c-6541cca3debe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial checkpoint saved to: /project/animesh_ray_1465/Zihao/GAN/logs/trial2/20251119-215817/checkpoints/ckpt-1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Skipping \\n# 1. Get the list of variables directly from your model object\\nmodel_vars = g_model.variables\\n\\n# 2. Get the list of variables from the checkpoint file\\nckpt_vars_raw = tf.train.list_variables(initial_ckpt_path)\\n\\n# 3. Filter for only the generator variables and sort them numerically\\nckpt_generator_vars = []\\nfor name, shape in ckpt_vars_raw:\\n    if name.startswith(\\'generator_variables/\\'):\\n        # Extract the numerical index for proper sorting\\n        index = int(re.search(r\\'(\\\\d+)\\', name).group(1))\\n        ckpt_generator_vars.append({\\'index\\': index, \\'name\\': name, \\'shape\\': shape})\\n\\n# Sort based on the extracted index\\nckpt_generator_vars.sort(key=lambda v: v[\\'index\\'])\\n\\nprint(f\"Found {len(model_vars)} variables in the model.\")\\nprint(f\"Found {len(ckpt_generator_vars)} variables in the checkpoint for the generator.\\n\")\\n\\nif len(model_vars) != len(ckpt_generator_vars):\\n    print(\"!!! MISMATCH in variable count! Checkpoint may be incomplete. !!!\")\\nelse:\\n    print(\"Variable count matches. Checking shapes...\\n\")\\n\\nprint(f\"{\\'Model Variable Name\\':<55} {\\'Model Shape\\':<20} {\\'Checkpoint Shape\\'}\")\\nprint(\"-\" * 100)\\n\\n# 4. Compare the two lists side-by-side\\nfor model_var, ckpt_var in zip(model_vars, ckpt_generator_vars):\\n    model_name = model_var.name\\n    model_shape = str(model_var.shape)\\n    ckpt_shape = str(ckpt_var[\\'shape\\'])\\n    \\n    # Check for MHA variables and highlight them\\n    highlight = \" <--- MHA Variable\" if \"attn\" in model_name else \"\"\\n    \\n    print(f\"{model_name:<55} {model_shape:<20} {ckpt_shape}{highlight}\")\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save an initial checkpoint (at step 0) and inspect variables\n",
    "initial_ckpt_path = ckpt_manager.save()\n",
    "print(f\"Initial checkpoint saved to: {initial_ckpt_path}\")\n",
    "# List all variable names in the saved checkpoint\n",
    "\"\"\"Skipping \n",
    "# 1. Get the list of variables directly from your model object\n",
    "model_vars = g_model.variables\n",
    "\n",
    "# 2. Get the list of variables from the checkpoint file\n",
    "ckpt_vars_raw = tf.train.list_variables(initial_ckpt_path)\n",
    "\n",
    "# 3. Filter for only the generator variables and sort them numerically\n",
    "ckpt_generator_vars = []\n",
    "for name, shape in ckpt_vars_raw:\n",
    "    if name.startswith('generator_variables/'):\n",
    "        # Extract the numerical index for proper sorting\n",
    "        index = int(re.search(r'(\\d+)', name).group(1))\n",
    "        ckpt_generator_vars.append({'index': index, 'name': name, 'shape': shape})\n",
    "\n",
    "# Sort based on the extracted index\n",
    "ckpt_generator_vars.sort(key=lambda v: v['index'])\n",
    "\n",
    "print(f\"Found {len(model_vars)} variables in the model.\")\n",
    "print(f\"Found {len(ckpt_generator_vars)} variables in the checkpoint for the generator.\\n\")\n",
    "\n",
    "if len(model_vars) != len(ckpt_generator_vars):\n",
    "    print(\"!!! MISMATCH in variable count! Checkpoint may be incomplete. !!!\")\n",
    "else:\n",
    "    print(\"Variable count matches. Checking shapes...\\n\")\n",
    "\n",
    "print(f\"{'Model Variable Name':<55} {'Model Shape':<20} {'Checkpoint Shape'}\")\n",
    "print(\"-\" * 100)\n",
    "\n",
    "# 4. Compare the two lists side-by-side\n",
    "for model_var, ckpt_var in zip(model_vars, ckpt_generator_vars):\n",
    "    model_name = model_var.name\n",
    "    model_shape = str(model_var.shape)\n",
    "    ckpt_shape = str(ckpt_var['shape'])\n",
    "    \n",
    "    # Check for MHA variables and highlight them\n",
    "    highlight = \" <--- MHA Variable\" if \"attn\" in model_name else \"\"\n",
    "    \n",
    "    print(f\"{model_name:<55} {model_shape:<20} {ckpt_shape}{highlight}\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "855a778b-e9af-484d-b972-14e5ca953f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_example(example_proto, seq_len=160, vocab_size=21):\n",
    "    feature_description = {\n",
    "        \"sequence\": tf.io.VarLenFeature(tf.int64),\n",
    "        \"label\": tf.io.FixedLenFeature([], tf.int64),  # parsed but unused\n",
    "    }\n",
    "    parsed = tf.io.parse_single_example(example_proto, feature_description)\n",
    "\n",
    "    sequence = tf.sparse.to_dense(parsed[\"sequence\"])\n",
    "    sequence = tf.cast(sequence, tf.int32)\n",
    "\n",
    "    # Clip or pad to fixed length\n",
    "    sequence = sequence[:seq_len]\n",
    "    paddings = [[0, tf.maximum(0, seq_len - tf.shape(sequence)[0])]]\n",
    "    sequence = tf.pad(sequence, paddings)\n",
    "\n",
    "    # One-hot encode → [seq_len, vocab_size] float32\n",
    "    one_hot = tf.one_hot(sequence, vocab_size)\n",
    "    return one_hot\n",
    "\n",
    "def load_tfrecord_dataset(\n",
    "    tfrecord_dir,\n",
    "    batch_size=8,\n",
    "    seq_len=160,\n",
    "    vocab_size=21,\n",
    "    shuffle_buffer=10000,\n",
    "    seed=42,\n",
    "    deterministic=True,\n",
    "    cycle_length=4,\n",
    "    drop_remainder=True,\n",
    "):\n",
    "    # Stable file order (DO NOT shuffle here)\n",
    "    files = sorted(tf.io.gfile.glob(os.path.join(tfrecord_dir, \"*.tfrecords\")))\n",
    "    if not files:\n",
    "        raise FileNotFoundError(f\"No .tfrecords under {tfrecord_dir}\")\n",
    "\n",
    "    ds_files = tf.data.Dataset.from_tensor_slices(files)\n",
    "\n",
    "    # Deterministic interleave over files\n",
    "    ds = ds_files.interleave(\n",
    "        lambda p: tf.data.TFRecordDataset(p),\n",
    "        cycle_length=cycle_length,\n",
    "        num_parallel_calls=tf.data.AUTOTUNE,\n",
    "        deterministic=deterministic,\n",
    "    )\n",
    "\n",
    "    ds = ds.map(\n",
    "        lambda ex: parse_example(ex, seq_len, vocab_size),\n",
    "        num_parallel_calls=tf.data.AUTOTUNE,\n",
    "    )\n",
    "\n",
    "    # Seeded shuffle; NO reshuffle each epoch → same order every run\n",
    "    if shuffle_buffer and shuffle_buffer > 0:\n",
    "        ds = ds.shuffle(\n",
    "            buffer_size=shuffle_buffer,\n",
    "            seed=seed,\n",
    "            reshuffle_each_iteration=False,\n",
    "        )\n",
    "\n",
    "    # Infinite stream with fixed batch shapes\n",
    "    ds = ds.batch(batch_size, drop_remainder=drop_remainder)\n",
    "    ds = ds.repeat()\n",
    "\n",
    "    # Enforce deterministic behavior at the pipeline level if requested\n",
    "    opts = tf.data.Options()\n",
    "    opts.deterministic = deterministic\n",
    "    ds = ds.with_options(opts)\n",
    "\n",
    "    ds = ds.prefetch(tf.data.AUTOTUNE)\n",
    "    return ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "62232c39-2f12-42bd-97ec-7bf5e22feb59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 160, 21)\n"
     ]
    }
   ],
   "source": [
    "dataset = load_tfrecord_dataset(\n",
    "    tfrecord_dir=\"/home1/zzhang201@kgi.edu/GAN/zzGAN/gan/data/zz/train\",\n",
    "    batch_size=FLAGS.batch_size,\n",
    "    seq_len=160,\n",
    "    seed=FLAGS.seed,\n",
    "    deterministic=True,  # flip to False if you want max throughput\n",
    ")\n",
    "\n",
    "batch = next(iter(dataset))\n",
    "print(batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6467608b-2aad-43bd-9bac-4998c3fe5bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define as tf.constant for Graph mode (matches your AMINO_ACIDS order)\n",
    "AA_MAP = tf.constant(['-', 'A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'W', 'Y'])\n",
    "\n",
    "def decode_sequence_tf(onehot):\n",
    "    \"\"\"TF-only version for single sequence: [L, V=21] → tf.string (b'ACDEF-...')\"\"\"\n",
    "    indices = tf.argmax(onehot, axis=-1)  # [L]\n",
    "    chars = tf.gather(AA_MAP, indices)    # [L] tf.strings like b'A', b'-'\n",
    "    return tf.strings.reduce_join(chars)  # Single tf.string\n",
    "\n",
    "def decode_batch_tf(batch_onehot):\n",
    "    \"\"\"\n",
    "    TF-only batch decode: [B, (1?), L, 21] → [B] tf.strings\n",
    "    Handles optional dim=1 squeeze.\n",
    "    \"\"\"\n",
    "    if batch_onehot.shape.rank == 4 and batch_onehot.shape[1] == 1:\n",
    "        batch_onehot = tf.squeeze(batch_onehot, axis=1)  # [B, L, 21]\n",
    "    return tf.map_fn(decode_sequence_tf, batch_onehot, dtype=tf.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c6fbe0bb-d41c-416a-b6c6-fcbbdeeec759",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In notebook init: Compute once\n",
    "real_embeds = []\n",
    "for _ in range(100):  # 100 batches = 6400 seqs\n",
    "    batch = next(iter(dataset))\n",
    "    seqs = decode_batch_tf(batch)\n",
    "    real_embeds.append(esm_embed([s.decode('utf-8') for s in seqs.numpy()]))\n",
    "MEAN_REAL_EMBED = tf.reduce_mean(tf.concat(real_embeds, axis=0), axis=0)  # [embed_dim]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3b55e219-dcf8-409f-b93c-ec1c4c397f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_discriminator_step(generator, discriminator, d_optimizer, real_batch, noise_dim, lambda_gp=10.0):\n",
    "    bsz  = tf.shape(real_batch)[0]\n",
    "    real = tf.cast(tf.expand_dims(real_batch, 1), tf.float32)     # [B,1,L,V]\n",
    "\n",
    "    z = tf.random.normal([bsz, noise_dim], dtype=tf.float32)\n",
    "    fake_soft = generator(z, training=True, return_hard=False)    # differentiable\n",
    "    fake = tf.stop_gradient(tf.cast(fake_soft, tf.float32))       # isolate D update\n",
    "\n",
    "    with tf.GradientTape(persistent=True) as disc_tape:\n",
    "        real_logits = discriminator(real, training=True)\n",
    "        fake_logits = discriminator(fake, training=True)\n",
    "\n",
    "        d_wgan = tf.reduce_mean(fake_logits) - tf.reduce_mean(real_logits)\n",
    "\n",
    "        # GP @ interpolated points\n",
    "        alpha = tf.random.uniform([bsz, 1, 1, 1], 0.0, 1.0, dtype=tf.float32)\n",
    "        inter = real + alpha * (fake - real)  # equivalent to alpha*real+(1-alpha)*fake\n",
    "        with tf.GradientTape() as gp_tape:\n",
    "            gp_tape.watch(inter)\n",
    "            inter_out = discriminator(inter, training=True)\n",
    "        inter_grads = gp_tape.gradient(inter_out, inter)\n",
    "        grad_norm   = tf.sqrt(tf.reduce_sum(tf.square(inter_grads), axis=[1,2,3]) + 1e-12)\n",
    "        gp          = tf.reduce_mean(tf.square(grad_norm - 1.0))\n",
    "\n",
    "        d_loss = d_wgan + lambda_gp * gp\n",
    "\n",
    "    d_vars  = discriminator.trainable_variables\n",
    "    d_grads = disc_tape.gradient(d_loss, d_vars)\n",
    "    d_grads = [tf.clip_by_norm(g, 1.0) if g is not None else g for g in d_grads]  # Clip D grads\n",
    "    d_missing = _count_missing_grads_t(d_grads)\n",
    "\n",
    "    # Filter None grads\n",
    "    pairs = [(g, v) for g, v in zip(d_grads, d_vars) if g is not None]\n",
    "    d_optimizer.apply_gradients(pairs)\n",
    "\n",
    "    d_grad_norm = tf.linalg.global_norm([g for g, _ in pairs]) if pairs else tf.constant(0., tf.float32)\n",
    "\n",
    "    # Also return means of logits to see separation\n",
    "    real_logit_mean = tf.reduce_mean(real_logits)\n",
    "    fake_logit_mean = tf.reduce_mean(fake_logits)\n",
    "\n",
    "    return d_loss, d_grad_norm, d_wgan, gp, d_missing, real_logit_mean, fake_logit_mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e2a8d061-a7e7-48f3-b7ad-c13bce2a65f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_generator_step(generator, discriminator, g_optimizer, noise_dim, entropy_weight=0.01):\n",
    "    bsz = FLAGS.batch_size\n",
    "    z = tf.random.normal([bsz, noise_dim], dtype=tf.float32)\n",
    "    with tf.GradientTape() as gen_tape:\n",
    "        # Run G once to fill last_logits\n",
    "        _ = generator(z, training=True, return_hard=False)\n",
    "        logits = getattr(generator, \"last_logits\", None)\n",
    "        if logits is not None:\n",
    "            p = tf.nn.softmax(tf.cast(logits, tf.float32), axis=-1) # [B,1,L,V]\n",
    "        else:\n",
    "            p = tf.cast(generator(z, training=True, return_hard=False), tf.float32)\n",
    "        fake_logits_D = discriminator(p, training=True)\n",
    "        g_adv = -tf.reduce_mean(fake_logits_D)\n",
    "        entropy_pos = -tf.reduce_sum(p * tf.math.log(tf.clip_by_value(p, 1e-8, 1.0)), axis=-1) # [B,1,L]\n",
    "        entropy = tf.reduce_mean(entropy_pos)\n",
    "        g_loss = g_adv - entropy_weight * entropy\n",
    "           \n",
    "    g_vars = generator.trainable_variables\n",
    "    g_grads = gen_tape.gradient(g_loss, g_vars)\n",
    "    g_missing = _count_missing_grads_t(g_grads)\n",
    "    g_grads = [tf.clip_by_norm(g, 1.0) if g is not None else g for g in g_grads]\n",
    "    pairs = [(g, v) for g, v in zip(g_grads, g_vars) if g is not None]\n",
    "    g_optimizer.apply_gradients(pairs)\n",
    "    # EMA after G update (if you use EMA)\n",
    "    ema.update(generator)\n",
    "    g_grad_norm = tf.linalg.global_norm([g for g, _ in pairs]) if pairs else tf.constant(0., tf.float32)\n",
    "    return g_loss, g_grad_norm, g_missing, entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aff8a24c-3ee2-468a-bf24-0774718b47f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Small manifest to catch accidental drift\\nimport json, platform\\nmanifest = {\\n    \"timestamp\": timestamp,\\n    \"mode\": \"resume\" if RESUME_FROM else (\"finetune\" if FINETUNE_FROM else \"fresh\"),\\n    \"resume_from\": RESUME_FROM,\\n    \"finetune_from\": FINETUNE_FROM,\\n    \"seed\": int(FLAGS.seed),\\n    \"z_dim\": int(FLAGS.z_dim),\\n    \"batch_size\": int(FLAGS.batch_size),\\n    \"ema\": bool(USE_EMA),\\n    \"ema_decay\": float(EMA_DECAY),\\n    \"lr_g\": float(getattr(g_opt.learning_rate, \"numpy\", lambda: g_opt.learning_rate)()),\\n    \"lr_d\": float(getattr(d_opt.learning_rate, \"numpy\", lambda: d_opt.learning_rate)()),\\n    \"python\": platform.python_version(),\\n    \"tensorflow\": tf.__version__,\\n}\\nwith open(os.path.join(run_dir, \"run_manifest.json\"), \"w\") as f:\\n    json.dump(manifest, f, indent=2)\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# Small manifest to catch accidental drift\n",
    "import json, platform\n",
    "manifest = {\n",
    "    \"timestamp\": timestamp,\n",
    "    \"mode\": \"resume\" if RESUME_FROM else (\"finetune\" if FINETUNE_FROM else \"fresh\"),\n",
    "    \"resume_from\": RESUME_FROM,\n",
    "    \"finetune_from\": FINETUNE_FROM,\n",
    "    \"seed\": int(FLAGS.seed),\n",
    "    \"z_dim\": int(FLAGS.z_dim),\n",
    "    \"batch_size\": int(FLAGS.batch_size),\n",
    "    \"ema\": bool(USE_EMA),\n",
    "    \"ema_decay\": float(EMA_DECAY),\n",
    "    \"lr_g\": float(getattr(g_opt.learning_rate, \"numpy\", lambda: g_opt.learning_rate)()),\n",
    "    \"lr_d\": float(getattr(d_opt.learning_rate, \"numpy\", lambda: d_opt.learning_rate)()),\n",
    "    \"python\": platform.python_version(),\n",
    "    \"tensorflow\": tf.__version__,\n",
    "}\n",
    "with open(os.path.join(run_dir, \"run_manifest.json\"), \"w\") as f:\n",
    "    json.dump(manifest, f, indent=2)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d3d89b9a-199b-44e8-990c-ac7c986f9dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import csv\n",
    "import re\n",
    "\n",
    "FASTA_PATH = Path(GENS_DIR) / \"generated_sequences.fasta\"\n",
    "INDEX_PATH = Path(GENS_DIR) / \"generated_sequences_index.csv\"\n",
    "\n",
    "# Write CSV header once if file is new\n",
    "if not INDEX_PATH.exists():\n",
    "    with open(INDEX_PATH, \"w\", newline=\"\") as f:\n",
    "        csv.writer(f).writerow([\"step\",\"seq_idx\",\"length\"])\n",
    "        \n",
    "AA = set(\"ACDEFGHIKLMNPQRSTVWYXBZ-\")\n",
    "def sanitize_seq(s: str) -> str:\n",
    "    s = re.sub(r\"\\s+\", \"\", s).upper()\n",
    "    return \"\".join(ch for ch in s if ch in AA)\n",
    "\n",
    "def append_generated_sequences(step: int, sequences):\n",
    "    \"\"\"Append sequences to FASTA + index CSV. Header stores the step + idx.\"\"\"\n",
    "    with open(FASTA_PATH, \"a\") as ffa, open(INDEX_PATH, \"a\", newline=\"\") as fcsv:\n",
    "        w = csv.writer(fcsv)\n",
    "        for i, s in enumerate(sequences):\n",
    "            seq = sanitize_seq(s)\n",
    "            header = f\"step{step:06d}_idx{i}\"\n",
    "            ffa.write(f\">{header}\\n{seq}\\n\")\n",
    "            w.writerow([step, i, len(seq)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4cd7b5f9-792f-4052-914c-08e5cd33d4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "AMINO_ACIDS = \"ACDEFGHIKLMNPQRSTVWY\"  # 20 residues\n",
    "AA_TO_IDX = {aa: i + 1 for i, aa in enumerate(AMINO_ACIDS)}\n",
    "PAD_IDX = 0\n",
    "VOCAB_SIZE = 21  # 0 (PAD) + 1–20\n",
    "\n",
    "MAX_LEN = 160\n",
    "\n",
    "def decode_sequence(onehot):\n",
    "    tokens = tf.argmax(onehot, axis=-1).numpy().flatten()\n",
    "    return ''.join([AMINO_ACIDS[i - 1] if i != 0 else '-' for i in tokens])\n",
    "\n",
    "def decode_batch(batch_tensor: tf.Tensor) -> list[str]:\n",
    "    \"\"\"\n",
    "    Decodes a batch of one-hot encoded tensors into amino acid sequences.\n",
    "\n",
    "    Supports input of shape:\n",
    "        - (B, 1, L, 21)\n",
    "        - (B, L, 21)\n",
    "\n",
    "    Returns:\n",
    "        List of decoded strings of length B\n",
    "    \"\"\"\n",
    "    if batch_tensor.shape.rank == 4:\n",
    "        batch_tensor = tf.squeeze(batch_tensor, axis=1)  # (B, L, 21)\n",
    "\n",
    "    return [decode_sequence(seq) for seq in batch_tensor]\n",
    "\n",
    "\n",
    "def encode_sequence(seq):\n",
    "    \"\"\"\n",
    "    Encode a sequence into one-hot with shape [1, MAX_LEN, 21]\n",
    "    \"\"\"\n",
    "    seq = seq.upper()\n",
    "    indices = [AA_TO_IDX.get(aa, PAD_IDX) for aa in seq[:MAX_LEN]]\n",
    "    if len(indices) < MAX_LEN:\n",
    "        indices += [PAD_IDX] * (MAX_LEN - len(indices))\n",
    "    one_hot = tf.one_hot(indices, depth=VOCAB_SIZE, dtype=tf.float32)  # [MAX_LEN, 21]\n",
    "    return tf.expand_dims(one_hot, axis=0)  # [1, MAX_LEN, 21]\n",
    "\n",
    "def encode_batch(sequences):\n",
    "    \"\"\"\n",
    "    Encode a batch of sequences -> [B, 1, MAX_LEN, 21]\n",
    "    \"\"\"\n",
    "    encoded = [encode_sequence(seq) for seq in sequences]\n",
    "    return tf.stack(encoded, axis=0)  # [B, 1, MAX_LEN, 21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1a55a1e3-4770-40bf-a81c-8641cbc1e623",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_aa_distribution(batch):\n",
    "    \"\"\"\n",
    "    Compute normalized amino acid distribution from a one-hot batch,\n",
    "    excluding padding (index 0). Supports shape (B, 1, L, 21) or (B, L, 21).\n",
    "    \"\"\"\n",
    "    if batch.shape.rank == 4:\n",
    "        batch = tf.squeeze(batch, axis=1)  # → (B, L, 21)\n",
    "\n",
    "    batch = tf.cast(batch, tf.float32)\n",
    "    # Exclude padding channel (index 0)\n",
    "    batch = batch[..., 1:]  # → shape: (B, L, 20)\n",
    "\n",
    "    counts = tf.reduce_sum(batch, axis=[0, 1])  # → (20,)\n",
    "    total = tf.reduce_sum(counts)\n",
    "    prob = tf.where(total > 0, counts / total, tf.zeros_like(counts))\n",
    "    return prob.numpy()\n",
    "\n",
    "def js_divergence_per_position(real_batch, gen_batch):\n",
    "    \"\"\"\n",
    "    Computes JS divergence for each position along the sequence (excluding padding index).\n",
    "    Supports input shape (B, 1, L, 21) or (B, L, 21).\n",
    "    Returns: np.array of shape (L,) — JS divergence per position\n",
    "    \"\"\"\n",
    "    if real_batch.shape.rank == 4:\n",
    "        real_batch = tf.squeeze(real_batch, axis=1)\n",
    "    if gen_batch.shape.rank == 4:\n",
    "        gen_batch = tf.squeeze(gen_batch, axis=1)\n",
    "\n",
    "    real_batch = tf.cast(real_batch, tf.float32).numpy()\n",
    "    gen_batch = tf.cast(gen_batch, tf.float32).numpy()\n",
    "\n",
    "    L = real_batch.shape[1]\n",
    "    jsd_pos = []\n",
    "\n",
    "    for i in range(L):\n",
    "        p_real = np.mean(real_batch[:, i, 1:], axis=0)  # exclude padding (index 0)\n",
    "        p_gen = np.mean(gen_batch[:, i, 1:], axis=0)\n",
    "        p_real /= np.sum(p_real) + 1e-8\n",
    "        p_gen /= np.sum(p_gen) + 1e-8\n",
    "        jsd = jensenshannon(p_real, p_gen, base=2)\n",
    "        jsd_pos.append(jsd)\n",
    "    \n",
    "    return np.array(jsd_pos)\n",
    "\n",
    "def sequence_lengths(onehot_batch):\n",
    "    indices = tf.argmax(onehot_batch, axis=-1)\n",
    "    non_padding = tf.not_equal(indices, 0)\n",
    "    return tf.reduce_sum(tf.cast(non_padding, tf.int32), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8a37eb7c-d89d-4304-b1ce-ba13017cbe70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalized_hamming_distance(seq1, seq2):\n",
    "    \"\"\"Compute normalized Hamming distance between two equal-length strings.\"\"\"\n",
    "    assert len(seq1) == len(seq2), \"Sequences must be the same length\"\n",
    "    return sum(a != b for a, b in zip(seq1, seq2)) / len(seq1)\n",
    "\n",
    "def filter_diverse_sequences(sequences, threshold=0.05, max_count=None):\n",
    "    diverse = []\n",
    "    for seq in sequences:\n",
    "        if all(normalized_hamming_distance(seq, d) >= threshold for d in diverse):\n",
    "            diverse.append(seq)\n",
    "        if max_count is not None and len(diverse) >= max_count:\n",
    "            break\n",
    "    return diverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d7ce38a1-383e-4f18-a76d-f00526421cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally pass amino acid sequence if you want labels\n",
    "def save_attention_png(attn, filename=\"attn_map.png\", aa_seq=None):\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    plt.imshow(attn, cmap='viridis')\n",
    "    plt.title(\"Attention Heatmap\")\n",
    "    if aa_seq:\n",
    "        plt.xticks(ticks=range(len(aa_seq)), labels=list(aa_seq), fontsize=6, rotation=90)\n",
    "        plt.yticks(ticks=range(len(aa_seq)), labels=list(aa_seq), fontsize=6)\n",
    "    else:\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filename)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "02600cd7-8e4b-4e06-be87-b959ac54b7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_attention_to_disk(attn_scores, sequences, step, output_dir=\"attn_logs\"):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    for i in range(attn_scores.shape[0]):\n",
    "        sample_path = os.path.join(output_dir, f\"sample_{i}_step_{step}.npz\")\n",
    "        np.savez_compressed(sample_path,\n",
    "                            attn=attn_scores[i].numpy(),  # shape [H, W, W]\n",
    "                            sequence=sequences[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "59b88631-e295-4874-b7f4-431081850047",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_attention_to_tensorboard(attn_scores, sequences, step, summary_writer):\n",
    "    \"\"\"\n",
    "    attn_scores: Tensor [B, H, W, W]\n",
    "    sequences: list of strings\n",
    "    \"\"\"\n",
    "    B, H, W, _ = attn_scores.shape\n",
    "    attn_scores = attn_scores.numpy()  # Convert for plotting\n",
    "    with summary_writer.as_default():\n",
    "        for i in range(min(B, 2)):  # log up to 2 samples\n",
    "            for h in range(H):\n",
    "                fig, ax = plt.subplots(figsize=(6, 6), dpi=100)\n",
    "                attn = attn_scores[i, h]  # [W, W]\n",
    "                im = ax.imshow(attn, cmap='magma', vmin=0.0, vmax=1.0)\n",
    "\n",
    "                ax.set_title(f\"Sample {i}, Head {h}\")\n",
    "                ax.set_xlabel(\"Residue Index\")\n",
    "                ax.set_ylabel(\"Residue Index\")\n",
    "\n",
    "                # Show ticks every 20 residues for readability\n",
    "                tick_positions = np.arange(0, W, 20)\n",
    "                ax.set_xticks(tick_positions)\n",
    "                ax.set_yticks(tick_positions)\n",
    "\n",
    "                # Optional: sequence length overlay\n",
    "                seq_len = len(sequences[i].replace(\"-\", \"\"))\n",
    "                ax.axvline(seq_len, color='white', linestyle='--', linewidth=1)\n",
    "                ax.axhline(seq_len, color='white', linestyle='--', linewidth=1)\n",
    "\n",
    "                plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "                plt.tight_layout()\n",
    "\n",
    "                # Save to TensorBoard\n",
    "                buf = io.BytesIO()\n",
    "                plt.savefig(buf, format='png')\n",
    "                plt.close(fig)\n",
    "                buf.seek(0)\n",
    "\n",
    "                image = tf.image.decode_png(buf.getvalue(), channels=4)\n",
    "                image = tf.expand_dims(image, 0)\n",
    "                tf.summary.image(f\"AttentionMaps/Sample{i}_Head{h}\", image, step=step)\n",
    "\n",
    "            tf.summary.text(f\"Attention/Sequence_{i}\", tf.convert_to_tensor([sequences[i]]), step=step)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f7c89612-ede3-462c-b597-53d4f818dc37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# --- ESM eval setup (PyTorch) ---\\nimport torch, numpy as np, matplotlib.pyplot as plt\\nfrom scipy.linalg import sqrtm\\nimport umap\\nimport esm\\n\\n# Config knobs (can be FLAGS if you prefer)\\nESM_MODEL_NAME = getattr(FLAGS, \"esm_model\", \"esm2_t6_8M_UR50D\")  # small & fast\\nESM_DEVICE     = getattr(FLAGS, \"esm_device\", \"cpu\")              # \"cpu\" is safe with TF; use \"cuda\" if you want\\nESM_BATCH      = getattr(FLAGS, \"esm_batch\", 64)\\nESM_EVAL_N     = getattr(FLAGS, \"esm_eval_n\", 128)                # sequences per class (real/gen) per eval\\n\\n# Load ESM once\\ndef _load_esm(name: str):\\n    name = name.strip()\\n    if name == \"esm2_t6_8M_UR50D\":\\n        m, A = esm.pretrained.esm2_t6_8M_UR50D(); layer = 6\\n    elif name == \"esm2_t12_35M_UR50D\":\\n        m, A = esm.pretrained.esm2_t12_35M_UR50D(); layer = 12\\n    else:\\n        m, A = esm.pretrained.esm2_t6_8M_UR50D(); layer = 6\\n    return m.eval(), A, layer\\n\\n_ESM_MODEL, _ESM_ALPH, _ESM_LAYER = _load_esm(ESM_MODEL_NAME)\\n\\n# mean-pooled ESM embeddings from sequences (list[str])\\ndef esm_embed(seqs, model=_ESM_MODEL, alphabet=_ESM_ALPH, layer=_ESM_LAYER,\\n              batch_size=ESM_BATCH, device=ESM_DEVICE):\\n    model = model.to(device)\\n    bc = alphabet.get_batch_converter()\\n    vecs = []\\n    for i in range(0, len(seqs), batch_size):\\n        chunk = seqs[i:i+batch_size]\\n        labels, strs, toks = bc([(\"seq\", s) for s in chunk])\\n        toks = toks.to(device)\\n        with torch.no_grad():\\n            out = model(toks, repr_layers=[layer])\\n            rep = out[\"representations\"][layer][:, 1:-1, :].mean(1)  # drop CLS/EOS, mean over tokens\\n        vecs.append(rep.detach().cpu().numpy())\\n    return np.vstack(vecs) if vecs else np.zeros((0, 0), dtype=np.float32)\\n\\ndef frechet(mu1, C1, mu2, C2, eps=1e-6):\\n    C1 = C1 + np.eye(C1.shape[0]) * eps\\n    C2 = C2 + np.eye(C2.shape[0]) * eps\\n    diff = (mu1 - mu2)\\n    covmean = sqrtm(C1.dot(C2))\\n    if np.iscomplexobj(covmean): covmean = covmean.real\\n    return float(diff.dot(diff) + np.trace(C1 + C2 - 2 * covmean))\\n\\ndef esm_fid(E_real, E_gen):\\n    if len(E_real)==0 or len(E_gen)==0: return np.nan\\n    mu_r, C_r = E_real.mean(0), np.cov(E_real, rowvar=False)\\n    mu_g, C_g = E_gen.mean(0), np.cov(E_gen, rowvar=False)\\n    return frechet(mu_r, C_r, mu_g, C_g)\\n\\ndef _fig_to_img(fig, close=True):\\n    fig.canvas.draw()\\n    w, h = fig.canvas.get_width_height()\\n    img = np.frombuffer(fig.canvas.tostring_rgb(), dtype=np.uint8).reshape(h, w, 3)\\n    if close: plt.close(fig)\\n    return img\\n\\ndef esm_umap_image(E_real, E_gen, title=\"UMAP (ESM) Real vs Gen\"):\\n    if len(E_real)==0 or len(E_gen)==0:\\n        return None\\n    mapper = umap.UMAP(n_neighbors=30, min_dist=0.1, metric=\"cosine\", random_state=0)\\n    Zr = mapper.fit_transform(E_real)\\n    Zg = mapper.transform(E_gen)\\n    fig = plt.figure(figsize=(5, 4))\\n    plt.scatter(Zr[:,0], Zr[:,1], s=6, alpha=0.30, label=\"Real\")\\n    plt.scatter(Zg[:,0], Zg[:,1], s=8, alpha=0.70, label=\"Gen\")\\n    plt.legend(loc=\"best\"); plt.title(title); plt.tight_layout()\\n    return _fig_to_img(fig)\\n'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# --- ESM eval setup (PyTorch) ---\n",
    "import torch, numpy as np, matplotlib.pyplot as plt\n",
    "from scipy.linalg import sqrtm\n",
    "import umap\n",
    "import esm\n",
    "\n",
    "# Config knobs (can be FLAGS if you prefer)\n",
    "ESM_MODEL_NAME = getattr(FLAGS, \"esm_model\", \"esm2_t6_8M_UR50D\")  # small & fast\n",
    "ESM_DEVICE     = getattr(FLAGS, \"esm_device\", \"cpu\")              # \"cpu\" is safe with TF; use \"cuda\" if you want\n",
    "ESM_BATCH      = getattr(FLAGS, \"esm_batch\", 64)\n",
    "ESM_EVAL_N     = getattr(FLAGS, \"esm_eval_n\", 128)                # sequences per class (real/gen) per eval\n",
    "\n",
    "# Load ESM once\n",
    "def _load_esm(name: str):\n",
    "    name = name.strip()\n",
    "    if name == \"esm2_t6_8M_UR50D\":\n",
    "        m, A = esm.pretrained.esm2_t6_8M_UR50D(); layer = 6\n",
    "    elif name == \"esm2_t12_35M_UR50D\":\n",
    "        m, A = esm.pretrained.esm2_t12_35M_UR50D(); layer = 12\n",
    "    else:\n",
    "        m, A = esm.pretrained.esm2_t6_8M_UR50D(); layer = 6\n",
    "    return m.eval(), A, layer\n",
    "\n",
    "_ESM_MODEL, _ESM_ALPH, _ESM_LAYER = _load_esm(ESM_MODEL_NAME)\n",
    "\n",
    "# mean-pooled ESM embeddings from sequences (list[str])\n",
    "def esm_embed(seqs, model=_ESM_MODEL, alphabet=_ESM_ALPH, layer=_ESM_LAYER,\n",
    "              batch_size=ESM_BATCH, device=ESM_DEVICE):\n",
    "    model = model.to(device)\n",
    "    bc = alphabet.get_batch_converter()\n",
    "    vecs = []\n",
    "    for i in range(0, len(seqs), batch_size):\n",
    "        chunk = seqs[i:i+batch_size]\n",
    "        labels, strs, toks = bc([(\"seq\", s) for s in chunk])\n",
    "        toks = toks.to(device)\n",
    "        with torch.no_grad():\n",
    "            out = model(toks, repr_layers=[layer])\n",
    "            rep = out[\"representations\"][layer][:, 1:-1, :].mean(1)  # drop CLS/EOS, mean over tokens\n",
    "        vecs.append(rep.detach().cpu().numpy())\n",
    "    return np.vstack(vecs) if vecs else np.zeros((0, 0), dtype=np.float32)\n",
    "\n",
    "def frechet(mu1, C1, mu2, C2, eps=1e-6):\n",
    "    C1 = C1 + np.eye(C1.shape[0]) * eps\n",
    "    C2 = C2 + np.eye(C2.shape[0]) * eps\n",
    "    diff = (mu1 - mu2)\n",
    "    covmean = sqrtm(C1.dot(C2))\n",
    "    if np.iscomplexobj(covmean): covmean = covmean.real\n",
    "    return float(diff.dot(diff) + np.trace(C1 + C2 - 2 * covmean))\n",
    "\n",
    "def esm_fid(E_real, E_gen):\n",
    "    if len(E_real)==0 or len(E_gen)==0: return np.nan\n",
    "    mu_r, C_r = E_real.mean(0), np.cov(E_real, rowvar=False)\n",
    "    mu_g, C_g = E_gen.mean(0), np.cov(E_gen, rowvar=False)\n",
    "    return frechet(mu_r, C_r, mu_g, C_g)\n",
    "\n",
    "def _fig_to_img(fig, close=True):\n",
    "    fig.canvas.draw()\n",
    "    w, h = fig.canvas.get_width_height()\n",
    "    img = np.frombuffer(fig.canvas.tostring_rgb(), dtype=np.uint8).reshape(h, w, 3)\n",
    "    if close: plt.close(fig)\n",
    "    return img\n",
    "\n",
    "def esm_umap_image(E_real, E_gen, title=\"UMAP (ESM) Real vs Gen\"):\n",
    "    if len(E_real)==0 or len(E_gen)==0:\n",
    "        return None\n",
    "    mapper = umap.UMAP(n_neighbors=30, min_dist=0.1, metric=\"cosine\", random_state=0)\n",
    "    Zr = mapper.fit_transform(E_real)\n",
    "    Zg = mapper.transform(E_gen)\n",
    "    fig = plt.figure(figsize=(5, 4))\n",
    "    plt.scatter(Zr[:,0], Zr[:,1], s=6, alpha=0.30, label=\"Real\")\n",
    "    plt.scatter(Zg[:,0], Zg[:,1], s=8, alpha=0.70, label=\"Gen\")\n",
    "    plt.legend(loc=\"best\"); plt.title(title); plt.tight_layout()\n",
    "    return _fig_to_img(fig)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3f541a05-4250-4915-a23b-3ae14921f373",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_generated_sequences(g_model, z_dim, decode_batch_fn, target_n, per_call=128):\n",
    "    seqs = []\n",
    "    while len(seqs) < target_n:\n",
    "        z = tf.random.normal([min(per_call, target_n - len(seqs)), z_dim], dtype=tf.float32)\n",
    "        hard = g_model(z, training=False, return_hard=True)\n",
    "        hard = tf.squeeze(hard, axis=1)\n",
    "        seqs.extend(decode_batch_fn(hard))\n",
    "    return seqs[:target_n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cd861ca5-27dd-4508-ab4f-2e787458b14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "real_df = pd.read_csv(\"/home1/zzhang201@kgi.edu/GAN/zzGAN/gan/data/zz/sample_seqs.csv\")\n",
    "real_seqs = real_df[\"sequence\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ac1f7f2a-fdbc-496a-aa16-272f999031ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Diagnostics helpers ---\n",
    "import os, numpy as np\n",
    "from scipy.spatial.distance import jensenshannon\n",
    "\n",
    "def current_lr(opt):\n",
    "    \"\"\"Return a Python float for the optimizer LR regardless of schedule/variable/float.\"\"\"\n",
    "    lr = getattr(opt, \"lr\", None) or getattr(opt, \"learning_rate\", None)\n",
    "    try:\n",
    "        return float(tf.keras.backend.get_value(lr))\n",
    "    except Exception:\n",
    "        # e.g., schedules\n",
    "        return float(tf.keras.backend.get_value(lr(tf.cast(model.g_model.global_step, tf.float32))))\n",
    "\n",
    "def _count_missing_grads_t(grads):\n",
    "    # Tensor int32 count of None grads (safe inside @tf.function)\n",
    "    return tf.reduce_sum(tf.constant([1 if g is None else 0 for g in grads], dtype=tf.int32))\n",
    "\n",
    "for l in model.g_model.layers:\n",
    "    if hasattr(l, \"disable_sn\"):\n",
    "        l.disable_sn.assign(False)   # True to disable sn for debugging or False to re-enable\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d22fa27a-5148-42b7-8f6b-b39ee255a729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home1/zzhang201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/site-packages/tensorflow/python/util/deprecation.py:660: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home1/zzhang201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/site-packages/tensorflow/python/util/deprecation.py:660: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n",
      "2025-11-19 21:59:24.950408: W tensorflow/core/framework/op_kernel.cc:1827] INVALID_ARGUMENT: TypeError: Cannot iterate over a scalar tensor.\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home1/zzhang201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 268, in __call__\n",
      "    return func(device, token, args)\n",
      "\n",
      "  File \"/home1/zzhang201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 146, in __call__\n",
      "    outputs = self._call(device, args)\n",
      "\n",
      "  File \"/home1/zzhang201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 153, in _call\n",
      "    ret = self._func(*args)\n",
      "\n",
      "  File \"/home1/zzhang201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/tmp/SLURM_19504/__autograph_generated_filexv_w2gic.py\", line 58, in compute_esm_mse\n",
      "    gen_py = [ag__.if_exp(ag__.converted_call(ag__.ld(isinstance), (ag__.ld(g), ag__.ld(bytes)), None, fscope_2), lambda : ag__.converted_call(ag__.ld(str), (ag__.converted_call(ag__.ld(g).decode, ('utf-8',), None, fscope_2),), None, fscope_2), lambda : ag__.converted_call(ag__.ld(str), (ag__.ld(g),), None, fscope_2), 'ag__.converted_call(isinstance, (g, bytes), None, fscope_2)') for g in ag__.ld(gen_py_in)]\n",
      "\n",
      "  File \"/home1/zzhang201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/site-packages/tensorflow/python/framework/tensor.py\", line 325, in __iter__\n",
      "    first_dim = self._get_first_dim()\n",
      "\n",
      "  File \"/home1/zzhang201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/site-packages/tensorflow/python/framework/tensor.py\", line 333, in _get_first_dim\n",
      "    raise TypeError(\"Cannot iterate over a scalar tensor.\")\n",
      "\n",
      "TypeError: Cannot iterate over a scalar tensor.\n",
      "\n",
      "\n",
      "2025-11-19 21:59:24.950438: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: INVALID_ARGUMENT: TypeError: Cannot iterate over a scalar tensor.\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home1/zzhang201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 268, in __call__\n",
      "    return func(device, token, args)\n",
      "\n",
      "  File \"/home1/zzhang201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 146, in __call__\n",
      "    outputs = self._call(device, args)\n",
      "\n",
      "  File \"/home1/zzhang201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 153, in _call\n",
      "    ret = self._func(*args)\n",
      "\n",
      "  File \"/home1/zzhang201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/tmp/SLURM_19504/__autograph_generated_filexv_w2gic.py\", line 58, in compute_esm_mse\n",
      "    gen_py = [ag__.if_exp(ag__.converted_call(ag__.ld(isinstance), (ag__.ld(g), ag__.ld(bytes)), None, fscope_2), lambda : ag__.converted_call(ag__.ld(str), (ag__.converted_call(ag__.ld(g).decode, ('utf-8',), None, fscope_2),), None, fscope_2), lambda : ag__.converted_call(ag__.ld(str), (ag__.ld(g),), None, fscope_2), 'ag__.converted_call(isinstance, (g, bytes), None, fscope_2)') for g in ag__.ld(gen_py_in)]\n",
      "\n",
      "  File \"/home1/zzhang201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/site-packages/tensorflow/python/framework/tensor.py\", line 325, in __iter__\n",
      "    first_dim = self._get_first_dim()\n",
      "\n",
      "  File \"/home1/zzhang201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/site-packages/tensorflow/python/framework/tensor.py\", line 333, in _get_first_dim\n",
      "    raise TypeError(\"Cannot iterate over a scalar tensor.\")\n",
      "\n",
      "TypeError: Cannot iterate over a scalar tensor.\n",
      "\n",
      "\n",
      "\t [[{{node EagerPyFunc_1}}]]\n",
      "2025-11-19 21:59:24.950454: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: INVALID_ARGUMENT: TypeError: Cannot iterate over a scalar tensor.\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home1/zzhang201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 268, in __call__\n",
      "    return func(device, token, args)\n",
      "\n",
      "  File \"/home1/zzhang201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 146, in __call__\n",
      "    outputs = self._call(device, args)\n",
      "\n",
      "  File \"/home1/zzhang201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 153, in _call\n",
      "    ret = self._func(*args)\n",
      "\n",
      "  File \"/home1/zzhang201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/tmp/SLURM_19504/__autograph_generated_filexv_w2gic.py\", line 58, in compute_esm_mse\n",
      "    gen_py = [ag__.if_exp(ag__.converted_call(ag__.ld(isinstance), (ag__.ld(g), ag__.ld(bytes)), None, fscope_2), lambda : ag__.converted_call(ag__.ld(str), (ag__.converted_call(ag__.ld(g).decode, ('utf-8',), None, fscope_2),), None, fscope_2), lambda : ag__.converted_call(ag__.ld(str), (ag__.ld(g),), None, fscope_2), 'ag__.converted_call(isinstance, (g, bytes), None, fscope_2)') for g in ag__.ld(gen_py_in)]\n",
      "\n",
      "  File \"/home1/zzhang201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/site-packages/tensorflow/python/framework/tensor.py\", line 325, in __iter__\n",
      "    first_dim = self._get_first_dim()\n",
      "\n",
      "  File \"/home1/zzhang201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/site-packages/tensorflow/python/framework/tensor.py\", line 333, in _get_first_dim\n",
      "    raise TypeError(\"Cannot iterate over a scalar tensor.\")\n",
      "\n",
      "TypeError: Cannot iterate over a scalar tensor.\n",
      "\n",
      "\n",
      "\t [[{{node EagerPyFunc_1}}]]\n",
      "\t [[EagerPyFunc_1/_35]]\n",
      "2025-11-19 21:59:24.950465: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 5079280561450551515\n",
      "2025-11-19 21:59:24.950540: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 4389972330662077665\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node EagerPyFunc_1 defined at (most recent call last):\n  File \"/home1/zzhang201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n\n  File \"/home1/zzhang201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/runpy.py\", line 87, in _run_code\n\n  File \"/home1/zzhang201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/site-packages/ipykernel_launcher.py\", line 18, in <module>\n\n  File \"/home1/zzhang201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/home1/zzhang201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 739, in start\n\n  File \"/home1/zzhang201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 205, in start\n\n  File \"/home1/zzhang201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n\n  File \"/home1/zzhang201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n\n  File \"/home1/zzhang201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/asyncio/events.py\", line 80, in _run\n\n  File \"/home1/zzhang201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n\n  File \"/home1/zzhang201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n\n  File \"/home1/zzhang201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n\n  File \"/home1/zzhang201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n\n  File \"/home1/zzhang201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n\n  File \"/home1/zzhang201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n\n  File \"/home1/zzhang201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/home1/zzhang201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3048, in run_cell\n\n  File \"/home1/zzhang201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3103, in _run_cell\n\n  File \"/home1/zzhang201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"/home1/zzhang201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3308, in run_cell_async\n\n  File \"/home1/zzhang201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3490, in run_ast_nodes\n\n  File \"/home1/zzhang201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3550, in run_code\n\n  File \"/tmp/SLURM_19504/ipykernel_1689219/252608413.py\", line 20, in <module>\n\n  File \"/tmp/SLURM_19504/ipykernel_1689219/1611085496.py\", line 33, in train_generator_step\n\nDetected at node EagerPyFunc_1 defined at (most recent call last):\n  File \"/home1/zzhang201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n\n  File \"/home1/zzhang201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/runpy.py\", line 87, in _run_code\n\n  File \"/home1/zzhang201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/site-packages/ipykernel_launcher.py\", line 18, in <module>\n\n  File \"/home1/zzhang201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/home1/zzhang201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 739, in start\n\n  File \"/home1/zzhang201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 205, in start\n\n  File \"/home1/zzhang201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n\n  File \"/home1/zzhang201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n\n  File \"/home1/zzhang201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/asyncio/events.py\", line 80, in _run\n\n  File \"/home1/zzhang201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n\n  File \"/home1/zzhang201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n\n  File \"/home1/zzhang201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n\n  File \"/home1/zzhang201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n\n  File \"/home1/zzhang201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n\n  File \"/home1/zzhang201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n\n  File \"/home1/zzhang201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/home1/zzhang201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3048, in run_cell\n\n  File \"/home1/zzhang201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3103, in _run_cell\n\n  File \"/home1/zzhang201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"/home1/zzhang201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3308, in run_cell_async\n\n  File \"/home1/zzhang201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3490, in run_ast_nodes\n\n  File \"/home1/zzhang201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3550, in run_code\n\n  File \"/tmp/SLURM_19504/ipykernel_1689219/252608413.py\", line 20, in <module>\n\n  File \"/tmp/SLURM_19504/ipykernel_1689219/1611085496.py\", line 33, in train_generator_step\n\n2 root error(s) found.\n  (0) INVALID_ARGUMENT:  TypeError: Cannot iterate over a scalar tensor.\nTraceback (most recent call last):\n\n  File \"/home1/zzhang201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 268, in __call__\n    return func(device, token, args)\n\n  File \"/home1/zzhang201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 146, in __call__\n    outputs = self._call(device, args)\n\n  File \"/home1/zzhang201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 153, in _call\n    ret = self._func(*args)\n\n  File \"/home1/zzhang201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/tmp/SLURM_19504/__autograph_generated_filexv_w2gic.py\", line 58, in compute_esm_mse\n    gen_py = [ag__.if_exp(ag__.converted_call(ag__.ld(isinstance), (ag__.ld(g), ag__.ld(bytes)), None, fscope_2), lambda : ag__.converted_call(ag__.ld(str), (ag__.converted_call(ag__.ld(g).decode, ('utf-8',), None, fscope_2),), None, fscope_2), lambda : ag__.converted_call(ag__.ld(str), (ag__.ld(g),), None, fscope_2), 'ag__.converted_call(isinstance, (g, bytes), None, fscope_2)') for g in ag__.ld(gen_py_in)]\n\n  File \"/home1/zzhang201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/site-packages/tensorflow/python/framework/tensor.py\", line 325, in __iter__\n    first_dim = self._get_first_dim()\n\n  File \"/home1/zzhang201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/site-packages/tensorflow/python/framework/tensor.py\", line 333, in _get_first_dim\n    raise TypeError(\"Cannot iterate over a scalar tensor.\")\n\nTypeError: Cannot iterate over a scalar tensor.\n\n\n\t [[{{node EagerPyFunc_1}}]]\n\t [[EagerPyFunc_1/_35]]\n  (1) INVALID_ARGUMENT:  TypeError: Cannot iterate over a scalar tensor.\nTraceback (most recent call last):\n\n  File \"/home1/zzhang201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 268, in __call__\n    return func(device, token, args)\n\n  File \"/home1/zzhang201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 146, in __call__\n    outputs = self._call(device, args)\n\n  File \"/home1/zzhang201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 153, in _call\n    ret = self._func(*args)\n\n  File \"/home1/zzhang201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/tmp/SLURM_19504/__autograph_generated_filexv_w2gic.py\", line 58, in compute_esm_mse\n    gen_py = [ag__.if_exp(ag__.converted_call(ag__.ld(isinstance), (ag__.ld(g), ag__.ld(bytes)), None, fscope_2), lambda : ag__.converted_call(ag__.ld(str), (ag__.converted_call(ag__.ld(g).decode, ('utf-8',), None, fscope_2),), None, fscope_2), lambda : ag__.converted_call(ag__.ld(str), (ag__.ld(g),), None, fscope_2), 'ag__.converted_call(isinstance, (g, bytes), None, fscope_2)') for g in ag__.ld(gen_py_in)]\n\n  File \"/home1/zzhang201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/site-packages/tensorflow/python/framework/tensor.py\", line 325, in __iter__\n    first_dim = self._get_first_dim()\n\n  File \"/home1/zzhang201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/site-packages/tensorflow/python/framework/tensor.py\", line 333, in _get_first_dim\n    raise TypeError(\"Cannot iterate over a scalar tensor.\")\n\nTypeError: Cannot iterate over a scalar tensor.\n\n\n\t [[{{node EagerPyFunc_1}}]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_generator_step_101271]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 20\u001b[0m\n\u001b[1;32m     15\u001b[0m     d_loss, d_grad_norm, d_wgan, d_gp, d_missing, d_real_m, d_fake_m \u001b[38;5;241m=\u001b[39m train_discriminator_step(\n\u001b[1;32m     16\u001b[0m         model\u001b[38;5;241m.\u001b[39mg_model, model\u001b[38;5;241m.\u001b[39md_model, model\u001b[38;5;241m.\u001b[39md_optim, real_batch, FLAGS\u001b[38;5;241m.\u001b[39mz_dim\n\u001b[1;32m     17\u001b[0m     )\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# --- Generator step ---\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m g_loss, g_grad_norm, g_missing, g_entropy, g_esm_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_generator_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mg_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43md_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mg_optim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mFLAGS\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mz_dim\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m model\u001b[38;5;241m.\u001b[39mglobal_step\u001b[38;5;241m.\u001b[39massign_add(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# === Light logging (every 100 steps) ===\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/tf2_16/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.conda/envs/tf2_16/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node EagerPyFunc_1 defined at (most recent call last):\n  File \"/home1/zzhang201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n\n  File \"/home1/zzhang201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/runpy.py\", line 87, in _run_code\n\n  File \"/home1/zzhang201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/site-packages/ipykernel_launcher.py\", line 18, in <module>\n\n  File \"/home1/zzhang201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/home1/zzhang201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 739, in start\n\n  File \"/home1/zzhang201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 205, in start\n\n  File \"/home1/zzhang201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n\n  File \"/home1/zzhang201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n\n  File \"/home1/zzhang201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/asyncio/events.py\", line 80, in _run\n\n  File \"/home1/zzhang201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n\n  File \"/home1/zzhang201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n\n  File \"/home1/zzhang201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n\n  File \"/home1/zzhang201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n\n  File \"/home1/zzhang201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n\n  File \"/home1/zzhang201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n\n  File \"/home1/zzhang201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/home1/zzhang201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3048, in run_cell\n\n  File \"/home1/zzhang201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3103, in _run_cell\n\n  File \"/home1/zzhang201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"/home1/zzhang201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3308, in run_cell_async\n\n  File \"/home1/zzhang201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3490, in run_ast_nodes\n\n  File \"/home1/zzhang201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3550, in run_code\n\n  File \"/tmp/SLURM_19504/ipykernel_1689219/252608413.py\", line 20, in <module>\n\n  File \"/tmp/SLURM_19504/ipykernel_1689219/1611085496.py\", line 33, in train_generator_step\n\nDetected at node EagerPyFunc_1 defined at (most recent call last):\n  File \"/home1/zzhang201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n\n  File \"/home1/zzhang201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/runpy.py\", line 87, in _run_code\n\n  File \"/home1/zzhang201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/site-packages/ipykernel_launcher.py\", line 18, in <module>\n\n  File \"/home1/zzhang201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/home1/zzhang201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 739, in start\n\n  File \"/home1/zzhang201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 205, in start\n\n  File \"/home1/zzhang201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n\n  File \"/home1/zzhang201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n\n  File \"/home1/zzhang201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/asyncio/events.py\", line 80, in _run\n\n  File \"/home1/zzhang201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n\n  File \"/home1/zzhang201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n\n  File \"/home1/zzhang201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n\n  File \"/home1/zzhang201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n\n  File \"/home1/zzhang201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n\n  File \"/home1/zzhang201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n\n  File \"/home1/zzhang201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/home1/zzhang201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3048, in run_cell\n\n  File \"/home1/zzhang201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3103, in _run_cell\n\n  File \"/home1/zzhang201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"/home1/zzhang201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3308, in run_cell_async\n\n  File \"/home1/zzhang201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3490, in run_ast_nodes\n\n  File \"/home1/zzhang201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3550, in run_code\n\n  File \"/tmp/SLURM_19504/ipykernel_1689219/252608413.py\", line 20, in <module>\n\n  File \"/tmp/SLURM_19504/ipykernel_1689219/1611085496.py\", line 33, in train_generator_step\n\n2 root error(s) found.\n  (0) INVALID_ARGUMENT:  TypeError: Cannot iterate over a scalar tensor.\nTraceback (most recent call last):\n\n  File \"/home1/zzhang201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 268, in __call__\n    return func(device, token, args)\n\n  File \"/home1/zzhang201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 146, in __call__\n    outputs = self._call(device, args)\n\n  File \"/home1/zzhang201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 153, in _call\n    ret = self._func(*args)\n\n  File \"/home1/zzhang201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/tmp/SLURM_19504/__autograph_generated_filexv_w2gic.py\", line 58, in compute_esm_mse\n    gen_py = [ag__.if_exp(ag__.converted_call(ag__.ld(isinstance), (ag__.ld(g), ag__.ld(bytes)), None, fscope_2), lambda : ag__.converted_call(ag__.ld(str), (ag__.converted_call(ag__.ld(g).decode, ('utf-8',), None, fscope_2),), None, fscope_2), lambda : ag__.converted_call(ag__.ld(str), (ag__.ld(g),), None, fscope_2), 'ag__.converted_call(isinstance, (g, bytes), None, fscope_2)') for g in ag__.ld(gen_py_in)]\n\n  File \"/home1/zzhang201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/site-packages/tensorflow/python/framework/tensor.py\", line 325, in __iter__\n    first_dim = self._get_first_dim()\n\n  File \"/home1/zzhang201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/site-packages/tensorflow/python/framework/tensor.py\", line 333, in _get_first_dim\n    raise TypeError(\"Cannot iterate over a scalar tensor.\")\n\nTypeError: Cannot iterate over a scalar tensor.\n\n\n\t [[{{node EagerPyFunc_1}}]]\n\t [[EagerPyFunc_1/_35]]\n  (1) INVALID_ARGUMENT:  TypeError: Cannot iterate over a scalar tensor.\nTraceback (most recent call last):\n\n  File \"/home1/zzhang201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 268, in __call__\n    return func(device, token, args)\n\n  File \"/home1/zzhang201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 146, in __call__\n    outputs = self._call(device, args)\n\n  File \"/home1/zzhang201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 153, in _call\n    ret = self._func(*args)\n\n  File \"/home1/zzhang201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/tmp/SLURM_19504/__autograph_generated_filexv_w2gic.py\", line 58, in compute_esm_mse\n    gen_py = [ag__.if_exp(ag__.converted_call(ag__.ld(isinstance), (ag__.ld(g), ag__.ld(bytes)), None, fscope_2), lambda : ag__.converted_call(ag__.ld(str), (ag__.converted_call(ag__.ld(g).decode, ('utf-8',), None, fscope_2),), None, fscope_2), lambda : ag__.converted_call(ag__.ld(str), (ag__.ld(g),), None, fscope_2), 'ag__.converted_call(isinstance, (g, bytes), None, fscope_2)') for g in ag__.ld(gen_py_in)]\n\n  File \"/home1/zzhang201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/site-packages/tensorflow/python/framework/tensor.py\", line 325, in __iter__\n    first_dim = self._get_first_dim()\n\n  File \"/home1/zzhang201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/site-packages/tensorflow/python/framework/tensor.py\", line 333, in _get_first_dim\n    raise TypeError(\"Cannot iterate over a scalar tensor.\")\n\nTypeError: Cannot iterate over a scalar tensor.\n\n\n\t [[{{node EagerPyFunc_1}}]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_generator_step_101271]"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "real_iter = iter(dataset)\n",
    "d_prev_k = None                       # for kernel delta probe\n",
    "ESM_EVAL_N = 512                      # adjust if you want more/less for FID\n",
    "\n",
    "# === Training Loop ===\n",
    "for step in range(FLAGS.steps):\n",
    "    # --- D:G ratio schedule ---\n",
    "    d_step = 1 if step < FLAGS.multid_schedule else FLAGS.d_step\n",
    "\n",
    "    # --- Discriminator steps ---\n",
    "    for _ in range(d_step):\n",
    "        real_batch = next(real_iter)\n",
    "        d_loss, d_grad_norm, d_wgan, d_gp, d_missing, d_real_m, d_fake_m = train_discriminator_step(\n",
    "            model.g_model, model.d_model, model.d_optim, real_batch, FLAGS.z_dim\n",
    "        )\n",
    "\n",
    "    # --- Generator step ---\n",
    "    g_loss, g_grad_norm, g_missing, g_entropy, g_esm_loss = train_generator_step(\n",
    "        model.g_model, model.d_model, model.g_optim, FLAGS.z_dim\n",
    "    )\n",
    "\n",
    "    model.global_step.assign_add(1)\n",
    "\n",
    "    # === Light logging (every 100 steps) ===\n",
    "    if (step + 1) % 100 == 0 or step == FLAGS.steps - 1:\n",
    "        clear_output(wait=True)\n",
    "        print(f\"[{step}] Generator Loss: {g_loss:.4f}, Discriminator Loss: {d_loss:.4f}\")\n",
    "        with summary_writer.as_default():\n",
    "            # D losses\n",
    "            tf.summary.scalar(\"D/total\",     d_loss,    step=step)\n",
    "            tf.summary.scalar(\"D/wgan\",      d_wgan,    step=step)\n",
    "            tf.summary.scalar(\"D/gp\",        d_gp,      step=step)\n",
    "            # G losses\n",
    "            tf.summary.scalar(\"G/total\",     g_loss,    step=step)\n",
    "            tf.summary.scalar(\"G/entropy\",   g_entropy, step=step)\n",
    "            tf.summary.scalar(\"G/esm_loss\",  g_esm_loss,  step=step)\n",
    "            # Grad norms & missing counts\n",
    "            tf.summary.scalar(\"D/grad_norm\", d_grad_norm, step=step)\n",
    "            tf.summary.scalar(\"G/grad_norm\", g_grad_norm, step=step)\n",
    "            tf.summary.scalar(\"D/missing_grads\", d_missing, step=step)\n",
    "            tf.summary.scalar(\"G/missing_grads\", g_missing, step=step)\n",
    "            # LRs\n",
    "            tf.summary.scalar(\"LR/D\", current_lr(model.d_optim), step=step)\n",
    "            tf.summary.scalar(\"LR/G\", current_lr(model.g_optim), step=step)\n",
    "            # D logits means\n",
    "            tf.summary.scalar(\"D/real_logit_mean\", d_real_m, step=step)\n",
    "            tf.summary.scalar(\"D/fake_logit_mean\", d_fake_m, step=step)\n",
    "\n",
    "    # === Heavier probes (every 1000 steps) ===\n",
    "    if (step + 1) % 1000 == 0 or step == FLAGS.steps - 1:\n",
    "        try:\n",
    "            k = model.d_model.get_layer(\"conv1\").kernel\n",
    "            delta = tf.constant(0.0, tf.float32)\n",
    "            if d_prev_k is not None:\n",
    "                delta = tf.norm(tf.cast(k, tf.float32) - tf.cast(d_prev_k, tf.float32))\n",
    "            d_prev_k = tf.identity(k)  # snapshot for next time\n",
    "            with summary_writer.as_default():\n",
    "                tf.summary.scalar(\"D/conv1_kernel_delta\", delta, step=step)\n",
    "        except Exception:\n",
    "            pass\n",
    "        # Generated sequence preview\n",
    "        z = tf.random.normal([8, FLAGS.z_dim], dtype=tf.float32)\n",
    "        samples = model.g_model(z, training=False, return_hard=True, return_attention=True)\n",
    "        samples = tf.squeeze(samples, axis=1)\n",
    "        sequences = [decode_sequence(seq) for seq in samples]\n",
    "        append_generated_sequences(step=step, sequences=sequences)\n",
    "\n",
    "        attn_scores = model.g_model.last_attn_scores\n",
    "        save_attention_to_disk(attn_scores, sequences, step, output_dir=attn_dir)\n",
    "        tf.print(\"\\n\".join(f\"Sample {i}: {sequences[i]}...\" for i in range(len(sequences))))\n",
    "\n",
    "    # === Quality metrics (every 500 steps) ===\n",
    "    if (step + 1) % 1000 == 0 or step == FLAGS.steps - 1:\n",
    "        # fresh batches for metrics (don’t rely on prior scope variables)\n",
    "        z = tf.random.normal([64, FLAGS.z_dim], dtype=tf.float32)\n",
    "        hard_batch = model.g_model(z, training=False, return_hard=True)\n",
    "        real_batch = next(real_iter)\n",
    "\n",
    "        gen_seqs  = decode_batch(hard_batch)\n",
    "        real_seqs = decode_batch(real_batch)\n",
    "\n",
    "        fr_loss, cdr_loss = quality_losses(gen_seqs, real_seqs, full_real_frs_csv=\"data/vh_regions.csv\")\n",
    "        anarci_stats = anarci_quality_log(gen_seqs)\n",
    "\n",
    "        p_gen  = get_aa_distribution(hard_batch)\n",
    "        p_real = get_aa_distribution(real_batch)\n",
    "        jsd    = jensenshannon(p_real, p_gen, base=2)\n",
    "\n",
    "        real_lengths = sequence_lengths(real_batch)\n",
    "        gen_lengths  = sequence_lengths(hard_batch)\n",
    "        jsd_pos      = js_divergence_per_position(real_batch, hard_batch)\n",
    "        valid_jsd    = jsd_pos[~np.isnan(jsd_pos)]\n",
    "        length_diff  = tf.reduce_mean(tf.cast(gen_lengths, tf.float32)) - tf.reduce_mean(tf.cast(real_lengths, tf.float32))\n",
    "\n",
    "        with summary_writer.as_default():\n",
    "            tf.summary.scalar(\"JS_Divergence/Aggregated\", jsd, step=step)\n",
    "            tf.summary.histogram(\"JS_Divergence/Per_Position\", jsd_pos, step=step)\n",
    "            tf.summary.scalar(\"JS_Divergence/Per_Position_Mean\", float(np.mean(valid_jsd)), step=step)\n",
    "            tf.summary.scalar(\"JS_Divergence/Per_Position_Max\",  float(np.max(valid_jsd)),  step=step)\n",
    "            tf.summary.scalar(\"JS_Divergence/Per_Position_Std\",  float(np.std(valid_jsd)),  step=step)\n",
    "\n",
    "            tf.summary.scalar(\"Length/Real_mean\",      tf.reduce_mean(real_lengths), step=step)\n",
    "            tf.summary.scalar(\"Length/Generated_mean\", tf.reduce_mean(gen_lengths),  step=step)\n",
    "            tf.summary.scalar(\"Length/Generated_stddev\", tf.math.reduce_std(tf.cast(gen_lengths, tf.float32)), step=step)\n",
    "            tf.summary.scalar(\"Length/Diff_Gen_minus_Real\", length_diff, step=step)\n",
    "\n",
    "            tf.summary.scalar(\"Anarci/FR_Loss\",      fr_loss, step=step)\n",
    "            tf.summary.scalar(\"Anarci/CDR_JS_Loss\",  cdr_loss, step=step)\n",
    "            tf.summary.scalar(\"Anarci/AnyHit\",       anarci_stats[\"full_hit\"] + anarci_stats[\"partial_hit\"], step=step)\n",
    "            tf.summary.scalar(\"Anarci/FullHit\",      anarci_stats[\"full_hit\"],     step=step)\n",
    "            tf.summary.scalar(\"Anarci/PartialHit\",   anarci_stats[\"partial_hit\"],  step=step)\n",
    "            tf.summary.scalar(\"Anarci/NoHit\",        anarci_stats[\"no_hit\"],       step=step)\n",
    "\n",
    "    # === Checkpointing ===\n",
    "    if (step + 1) % FLAGS.save_checkpoint_sec == 0 or step == FLAGS.steps - 1:\n",
    "        path = ckpt_manager.save()\n",
    "        print(f\"Checkpoint saved at step {step}: {path}\")\n",
    "\n",
    "    # === ESM eval (EMA), every 2500 steps ===\n",
    "    if (step + 1) % 2500 == 0 or step == FLAGS.steps - 1:\n",
    "        # Assemble fresh real/gen sets here so variables exist\n",
    "        # (don’t rely on `real_seqs` from another block)\n",
    "        # Real:\n",
    "        real_eval_batch = next(real_iter)\n",
    "        real_eval_seqs  = decode_batch(real_eval_batch)\n",
    "        # Gen (EMA weights):\n",
    "        with ema.average_parameters(model.g_model):\n",
    "            gen_eval_seqs = sample_generated_sequences(model.g_model, FLAGS.z_dim, decode_batch, ESM_EVAL_N)\n",
    "\n",
    "        E_r = esm_embed(real_eval_seqs)\n",
    "        E_g = esm_embed(gen_eval_seqs)\n",
    "        fid_esm = esm_fid(E_r, E_g)\n",
    "        umap_img = esm_umap_image(E_r, E_g, title=\"UMAP (ESM) Real vs Gen (EMA)\")\n",
    "\n",
    "        with summary_writer.as_default():\n",
    "            tf.summary.scalar(\"ESM/FID_EMA\", fid_esm, step=step)\n",
    "            if umap_img is not None:\n",
    "                tf.summary.image(\"UMAP_ESM/Real_vs_Gen_EMA\", umap_img[None, ...], step=step)\n",
    "\n",
    "    # === Finalization ===\n",
    "    if step == FLAGS.steps - 1:\n",
    "        with ema.average_parameters(model.g_model):\n",
    "            z = tf.random.normal([300, FLAGS.z_dim], dtype=tf.float32)\n",
    "            hard_batch = model.g_model(z, training=False, return_hard=True, return_attention=True)\n",
    "            hard_batch = tf.squeeze(hard_batch, axis=1)\n",
    "            sequences = [decode_sequence(seq) for seq in hard_batch]\n",
    "\n",
    "            diverse_seqs = filter_diverse_sequences(sequences, threshold=0.05, max_count=None)\n",
    "\n",
    "            # save a few attention maps\n",
    "            for i in range(min(4, len(sequences))):\n",
    "                for h in range(2):\n",
    "                    if model.g_model.last_attn_scores is not None:\n",
    "                        attn = model.g_model.last_attn_scores[i, h]  # [L, L]\n",
    "                        save_attention_png(attn.numpy(), filename=f\"attn_sample{i}_head{h}.png\", aa_seq=sequences[i])\n",
    "\n",
    "            with summary_writer.as_default():\n",
    "                for i, seq in enumerate(diverse_seqs[:30]):\n",
    "                    tf.summary.text(f\"Final/DiverseSequence_{i}\", tf.convert_to_tensor([seq]), step=step)\n",
    "                tf.summary.scalar(\"Final/NumDiverseSequences\", len(diverse_seqs), step=step)\n",
    "\n",
    "            print(f\"Generated {len(sequences)} sequences.\")\n",
    "            print(f\"Found {len(diverse_seqs)} diverse sequences.\")\n",
    "\n",
    "        summary_writer.flush()\n",
    "        generate_dynamic_layout(logdir=os.path.join(FLAGS.logdir, FLAGS.name), run_name=timestamp)\n",
    "        print(f\"Layout updated based on {log_dir}\")\n",
    "\n",
    "        final_path = ckpt_manager.save()\n",
    "        print(\"Final checkpoint saved:\", final_path)\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32551f7d-9301-475d-b1d5-c463905c9583",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367b2589-7f9c-4b2f-a64a-9271b6b1a9f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python (tf2_16)",
   "language": "python",
   "name": "tf2_16"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
