{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bf76c30-4cfb-42d2-ab59-8ff96dfb74e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "815d6199-17b2-4e8f-aede-60ae3c35d4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home1/zzhang201@kgi.edu/GAN/zzGAN/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29b016c6-6cd8-4b00-b56d-268d1abbd146",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-26 11:00:15.876907: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-26 11:00:15.909570: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# import tensorflow_gan as tfgan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c01e5ef2-45e5-4008-a99a-c108ba64dfa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF version: 2.16.1\n",
      "GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "print(\"TF version:\", tf.__version__)\n",
    "print(\"GPUs:\", tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f7a9d9f-d845-44f6-83e2-6bfb7996d386",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import jensenshannon\n",
    "import matplotlib.ticker as ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c767d0e-858f-4169-9d34-6951dbe77a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home1/ZZHANG201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import umap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33435abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import random\n",
    "import datetime\n",
    "import platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6785f0f-c59d-4899-b738-2ee049d2ecf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2052766",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import get_model, get_specific_hooks\n",
    "from parameters import get_flags\n",
    "from documentation import setup_logdir, get_properties\n",
    "from documentation import print_run_meta_data, add_model_metadata\n",
    "from tensorflow.keras import mixed_precision\n",
    "from tensorflow.keras.mixed_precision import LossScaleOptimizer\n",
    "# Enable global mixed precision policy\n",
    "mixed_precision.set_global_policy('mixed_float16')\n",
    "from protein.quality_gates import quality_losses, anarci_quality_log\n",
    "from protein.custom_scalars import generate_dynamic_layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0040c371-8a1c-4349-a3f1-b8bcc2b2ec73",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FakeFlags:\n",
    "    # General model setup\n",
    "    model_type = 'wgan'\n",
    "    architecture = 'gumbel'\n",
    "    batch_size = 64\n",
    "    z_dim = 128\n",
    "    gf_dim = 64\n",
    "    df_dim = 64\n",
    "    dim = gf_dim\n",
    "    attn_pos = 2\n",
    "\n",
    "    # Kernel and dilation config\n",
    "    kernel_height = 3\n",
    "    kernel_width = 3\n",
    "    dilation_rate = 2\n",
    "    pooling = 'conv'\n",
    "\n",
    "    # Optional: logging / save frequency\n",
    "    name = 'trial2'\n",
    "    steps = 200000\n",
    "    save_summary_steps = 1000\n",
    "    save_checkpoint_sec = 5000\n",
    "\n",
    "    # Optimizer settings\n",
    "    generator_learning_rate = 1e-4\n",
    "    discriminator_learning_rate = 5e-5\n",
    "    beta1 = 0.5\n",
    "    beta2 = 0.9\n",
    "\n",
    "    # Dataset & file structure\n",
    "    dataset = 'zz'\n",
    "    seq_length = 160\n",
    "    logdir = '/project/animesh_ray_1465/Zihao/GAN/logs'\n",
    "    # properties_file = 'properties.json'\n",
    "\n",
    "    # Misc\n",
    "    seed = 950806\n",
    "    resume_from = None\n",
    "    # finetune_from = '/home1/zzhang201@kgi.edu/GAN/zzGAN/logs/zz/multiG_attn_adjusted_embed/20250724-032823/'\n",
    "    multid_schedule = 20000\n",
    "    d_step = 3\n",
    "    shuffle_buffer_size = 1000\n",
    "    label_noise_level = 0.0\n",
    "    noise_level = 0.0\n",
    "    fm_weight = 1\n",
    "\n",
    "    def flag_values_dict(self):\n",
    "        return {k: getattr(self, k) for k in dir(self)\n",
    "                if not k.startswith(\"__\") and not callable(getattr(self, k))}\n",
    "FLAGS = FakeFlags()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "339bfacc-054f-48b8-b491-c4bbc50bb11c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-26 11:00:28.383202: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43622 MB memory:  -> device: 0, name: NVIDIA L40S, pci bus id: 0000:21:00.0, compute capability: 8.9\n",
      "2025-11-26 11:00:28.383744: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 43622 MB memory:  -> device: 1, name: NVIDIA L40S, pci bus id: 0000:e1:00.0, compute capability: 8.9\n"
     ]
    }
   ],
   "source": [
    "random.seed(FLAGS.seed)\n",
    "np.random.seed(FLAGS.seed)\n",
    "tf.random.set_seed(FLAGS.seed)\n",
    "# Fixed latent for eval snapshots so runs are comparable\n",
    "Z_EVAL = tf.random.stateless_normal([128, FLAGS.z_dim], seed=(950, 806))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "defe8e17-ad68-48a9-9124-8c8968a7b581",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_flags(flags, log_dir, filename=\"flags.json\"):\n",
    "    \"\"\"Save FLAGS to a JSON file in the log directory.\"\"\"\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "    file_path = os.path.join(log_dir, filename)\n",
    "\n",
    "    with open(file_path, \"w\") as f:\n",
    "        json.dump(flags.flag_values_dict(), f, indent=4)\n",
    "    \n",
    "    print(f\"[FLAGS] Saved flags to {file_path}\")\n",
    "\n",
    "def load_flags(log_dir, filename=\"flags.json\"):\n",
    "    \"\"\"Load FLAGS from JSON file and return as a FakeFlags object.\"\"\"\n",
    "    file_path = os.path.join(log_dir, filename)\n",
    "\n",
    "    if not os.path.exists(file_path):\n",
    "        raise FileNotFoundError(f\"[FLAGS] No flags file found at {file_path}\")\n",
    "\n",
    "    with open(file_path, \"r\") as f:\n",
    "        flag_dict = json.load(f)\n",
    "\n",
    "    # Create a new FakeFlags object and set attributes\n",
    "    loaded_flags = FakeFlags()\n",
    "    for k, v in flag_dict.items():\n",
    "        setattr(loaded_flags, k, v)\n",
    "\n",
    "    print(f\"[FLAGS] Loaded flags from {file_path}\")\n",
    "    return loaded_flags\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "01d532a0-2ebb-4502-8e0b-51d512fd2b30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home1/ZZHANG201@kgi.edu/.conda/envs/tf2_16/lib/python3.9/site-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
      "  warnings.warn(\n",
      "2025-11-26 11:00:30.242723: E tensorflow/core/util/util.cc:131] oneDNN supports DT_HALF only on platforms with AVX-512. Falling back to the default Eigen-based implementation if present.\n",
      "2025-11-26 11:00:31.057801: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing from scratch.\n",
      "[FLAGS] Saved flags to /project/animesh_ray_1465/Zihao/GAN/logs/trial2/20251126-110028/summaries/flags.json\n"
     ]
    }
   ],
   "source": [
    "import os, json, datetime, tensorflow as tf\n",
    "from protein.ema import EMA\n",
    "# 0) Make run dirs first (RUN_DIR, CKPT_DIR, SUMM_DIR, ATTN_DIR, etc.)\n",
    "timestamp   = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "RUN_DIR     = os.path.join(FLAGS.logdir, FLAGS.name, timestamp)\n",
    "CKPT_DIR    = os.path.join(RUN_DIR, \"checkpoints\")\n",
    "SUMM_DIR    = os.path.join(RUN_DIR, \"summaries\")\n",
    "ATTN_DIR    = os.path.join(RUN_DIR, \"attn_scores\")\n",
    "GENS_DIR    = os.path.join(RUN_DIR, \"generated\")\n",
    "\n",
    "for d in (CKPT_DIR, SUMM_DIR, ATTN_DIR, GENS_DIR):\n",
    "    os.makedirs(d, exist_ok=True)\n",
    "\n",
    "# 1) Build models/opts (objects only; no variables yet)\n",
    "noise = tf.random.normal([FLAGS.batch_size, FLAGS.z_dim], dtype=tf.float32)\n",
    "model = get_model(FLAGS, RUN_DIR, noise)\n",
    "g_model, d_model = model.g_model, model.d_model\n",
    "g_opt, d_opt     = model.g_optim, model.d_optim\n",
    "\n",
    "# 2) Global step (int32 to match old ckpts) and attach to G\n",
    "global_step = tf.Variable(0, dtype=tf.int32, name=\"global_step\")\n",
    "setattr(g_model, \"global_step\", global_step)\n",
    "\n",
    "# 3) WARM-UP once in fp32 to create ALL variables eagerly (prevents trace/deferred issues)\n",
    "_ = g_model(tf.random.normal([1, FLAGS.z_dim], dtype=tf.float32), training=False, return_hard=False)\n",
    "SEQ_LEN = getattr(FLAGS, \"seq_len\", 160)\n",
    "VOCAB   = getattr(FLAGS, \"vocab_size\", 21)\n",
    "_ = d_model(tf.random.normal([1, 1, SEQ_LEN, VOCAB], dtype=tf.float32), training=False)\n",
    "\n",
    "# 4) Create EMA object and **build it now** (so shadows exist for restore)\n",
    "ema = EMA(decay=getattr(FLAGS, \"ema_decay\", 0.999))\n",
    "ema.build(g_model)   # shadows initialized from current g_model weights (fp32)\n",
    "\n",
    "# 5) Create a checkpoint that includes models, optimizers, step, and EMA\n",
    "# We now explicitly pass the generator's list of variables\n",
    "ckpt = tf.train.Checkpoint(\n",
    "    generator_variables=g_model.variables,  # The FIX: Pass the variable list directly\n",
    "    discriminator=d_model,\n",
    "    g_optimizer=g_opt,\n",
    "    d_optimizer=d_opt,\n",
    "    step=global_step,\n",
    "    ema=ema\n",
    ")\n",
    "\n",
    "# 6) Restore (if any). Use a *temporary manager* pointed at the SOURCE dir.\n",
    "RESUME_FROM   = getattr(FLAGS, \"resume_from\", None)\n",
    "FINETUNE_FROM = getattr(FLAGS, \"finetune_from\", None)\n",
    "\n",
    "def _restore_from(src_dir, label):\n",
    "    src_mgr = tf.train.CheckpointManager(ckpt, os.path.join(src_dir, \"checkpoints\"), max_to_keep=5)\n",
    "    if not src_mgr.latest_checkpoint:\n",
    "        raise FileNotFoundError(f\"No checkpoint found in {src_dir}/checkpoints\")\n",
    "    status = ckpt.restore(src_mgr.latest_checkpoint)\n",
    "    status.expect_partial()  # OK: SN u-vectors & (possibly) EMA may differ\n",
    "    print(f\"[{label}] restored:\", src_mgr.latest_checkpoint)\n",
    "\n",
    "if RESUME_FROM:\n",
    "    _restore_from(RESUME_FROM, \"RESUME\")      # same run, same objective → restores opts + EMA if present\n",
    "elif FINETUNE_FROM:\n",
    "    _restore_from(FINETUNE_FROM, \"FINETUNE\")  # see weights-only variant below if you don't want optimizer state\n",
    "else:\n",
    "    print(\"Initializing from scratch.\")\n",
    "\n",
    "# 7) Destination manager for THIS run (saves to your new RUN_DIR)\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, CKPT_DIR, max_to_keep=5)\n",
    "\n",
    "# 8) Summary writer\n",
    "summary_writer = tf.summary.create_file_writer(SUMM_DIR)\n",
    "\n",
    "# 9) Save flags, expose paths\n",
    "save_flags(FLAGS, SUMM_DIR)\n",
    "attn_dir = ATTN_DIR\n",
    "log_dir  = RUN_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "25eb59dd-b1e0-4313-a26c-6541cca3debe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial checkpoint saved to: /project/animesh_ray_1465/Zihao/GAN/logs/trial2/20251126-110028/checkpoints/ckpt-1\n"
     ]
    }
   ],
   "source": [
    "# Save an initial checkpoint (at step 0) and inspect variables\n",
    "initial_ckpt_path = ckpt_manager.save()\n",
    "print(f\"Initial checkpoint saved to: {initial_ckpt_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "855a778b-e9af-484d-b972-14e5ca953f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_example(example_proto, seq_len=160, vocab_size=21):\n",
    "    feature_description = {\n",
    "        \"sequence\": tf.io.VarLenFeature(tf.int64),\n",
    "        \"label\": tf.io.FixedLenFeature([], tf.int64),  # parsed but unused\n",
    "    }\n",
    "    parsed = tf.io.parse_single_example(example_proto, feature_description)\n",
    "\n",
    "    sequence = tf.sparse.to_dense(parsed[\"sequence\"])\n",
    "    sequence = tf.cast(sequence, tf.int32)\n",
    "\n",
    "    # Clip or pad to fixed length\n",
    "    sequence = sequence[:seq_len]\n",
    "    paddings = [[0, tf.maximum(0, seq_len - tf.shape(sequence)[0])]]\n",
    "    sequence = tf.pad(sequence, paddings)\n",
    "\n",
    "    # One-hot encode → [seq_len, vocab_size] float32\n",
    "    one_hot = tf.one_hot(sequence, vocab_size)\n",
    "    return one_hot\n",
    "\n",
    "def load_tfrecord_dataset(\n",
    "    tfrecord_dir,\n",
    "    batch_size=8,\n",
    "    seq_len=160,\n",
    "    vocab_size=21,\n",
    "    shuffle_buffer=10000,\n",
    "    seed=42,\n",
    "    deterministic=True,\n",
    "    cycle_length=4,\n",
    "    drop_remainder=True,\n",
    "):\n",
    "    # Stable file order (DO NOT shuffle here)\n",
    "    files = sorted(tf.io.gfile.glob(os.path.join(tfrecord_dir, \"*.tfrecords\")))\n",
    "    if not files:\n",
    "        raise FileNotFoundError(f\"No .tfrecords under {tfrecord_dir}\")\n",
    "\n",
    "    ds_files = tf.data.Dataset.from_tensor_slices(files)\n",
    "\n",
    "    # Deterministic interleave over files\n",
    "    ds = ds_files.interleave(\n",
    "        lambda p: tf.data.TFRecordDataset(p),\n",
    "        cycle_length=cycle_length,\n",
    "        num_parallel_calls=tf.data.AUTOTUNE,\n",
    "        deterministic=deterministic,\n",
    "    )\n",
    "\n",
    "    ds = ds.map(\n",
    "        lambda ex: parse_example(ex, seq_len, vocab_size),\n",
    "        num_parallel_calls=tf.data.AUTOTUNE,\n",
    "    )\n",
    "\n",
    "    # Seeded shuffle; NO reshuffle each epoch → same order every run\n",
    "    if shuffle_buffer and shuffle_buffer > 0:\n",
    "        ds = ds.shuffle(\n",
    "            buffer_size=shuffle_buffer,\n",
    "            seed=seed,\n",
    "            reshuffle_each_iteration=False,\n",
    "        )\n",
    "\n",
    "    # Infinite stream with fixed batch shapes\n",
    "    ds = ds.batch(batch_size, drop_remainder=drop_remainder)\n",
    "    ds = ds.repeat()\n",
    "\n",
    "    # Enforce deterministic behavior at the pipeline level if requested\n",
    "    opts = tf.data.Options()\n",
    "    opts.deterministic = deterministic\n",
    "    ds = ds.with_options(opts)\n",
    "\n",
    "    ds = ds.prefetch(tf.data.AUTOTUNE)\n",
    "    return ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "62232c39-2f12-42bd-97ec-7bf5e22feb59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 160, 21)\n"
     ]
    }
   ],
   "source": [
    "dataset = load_tfrecord_dataset(\n",
    "    tfrecord_dir=\"/home1/ZZHANG201@kgi.edu/GAN/zzGAN/gan/data/zz/train\",\n",
    "    batch_size=FLAGS.batch_size,\n",
    "    seq_len=160,\n",
    "    seed=FLAGS.seed,\n",
    "    deterministic=True,  # flip to False if you want max throughput\n",
    ")\n",
    "\n",
    "batch = next(iter(dataset))\n",
    "print(batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3b55e219-dcf8-409f-b93c-ec1c4c397f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_discriminator_step(generator, discriminator, d_optimizer, real_batch, noise_dim, lambda_gp=10.0):\n",
    "    bsz  = tf.shape(real_batch)[0]\n",
    "    real = tf.cast(tf.expand_dims(real_batch, 1), tf.float32)     # [B,1,L,V]\n",
    "\n",
    "    z = tf.random.normal([bsz, noise_dim], dtype=tf.float32)\n",
    "    fake_soft = generator(z, training=True, return_hard=False)    # differentiable\n",
    "    fake = tf.stop_gradient(tf.cast(fake_soft, tf.float32))       # isolate D update\n",
    "\n",
    "    with tf.GradientTape(persistent=True) as disc_tape:\n",
    "        real_logits = discriminator(real, training=True)\n",
    "        fake_logits = discriminator(fake, training=True)\n",
    "\n",
    "        d_wgan = tf.reduce_mean(fake_logits) - tf.reduce_mean(real_logits)\n",
    "\n",
    "        # GP @ interpolated points\n",
    "        alpha = tf.random.uniform([bsz, 1, 1, 1], 0.0, 1.0, dtype=tf.float32)\n",
    "        inter = real + alpha * (fake - real)  # equivalent to alpha*real+(1-alpha)*fake\n",
    "        with tf.GradientTape() as gp_tape:\n",
    "            gp_tape.watch(inter)\n",
    "            inter_out = discriminator(inter, training=True)\n",
    "        inter_grads = gp_tape.gradient(inter_out, inter)\n",
    "        grad_norm   = tf.sqrt(tf.reduce_sum(tf.square(inter_grads), axis=[1,2,3]) + 1e-12)\n",
    "        gp          = tf.reduce_mean(tf.square(grad_norm - 1.0))\n",
    "\n",
    "        d_loss = d_wgan + lambda_gp * gp\n",
    "\n",
    "    d_vars  = discriminator.trainable_variables\n",
    "    d_grads = disc_tape.gradient(d_loss, d_vars)\n",
    "    d_missing = _count_missing_grads_t(d_grads)\n",
    "\n",
    "    # Filter None grads\n",
    "    pairs = [(g, v) for g, v in zip(d_grads, d_vars) if g is not None]\n",
    "    d_optimizer.apply_gradients(pairs)\n",
    "\n",
    "    d_grad_norm = tf.linalg.global_norm([g for g, _ in pairs]) if pairs else tf.constant(0., tf.float32)\n",
    "\n",
    "    # Also return means of logits to see separation\n",
    "    real_logit_mean = tf.reduce_mean(real_logits)\n",
    "    fake_logit_mean = tf.reduce_mean(fake_logits)\n",
    "\n",
    "    return d_loss, d_grad_norm, d_wgan, gp, d_missing, real_logit_mean, fake_logit_mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e2a8d061-a7e7-48f3-b7ad-c13bce2a65f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_generator_step(generator,\n",
    "                         discriminator,\n",
    "                         g_optimizer,\n",
    "                         noise_dim,\n",
    "                         real_batch,              # NEW: real inputs for feature matching\n",
    "                         entropy_weight=0.01,\n",
    "                         fm_weight=1.0):          # NEW: feature-matching weight\n",
    "    bsz = FLAGS.batch_size\n",
    "    z = tf.random.normal([bsz, noise_dim], dtype=tf.float32)\n",
    "\n",
    "    with tf.GradientTape() as gen_tape:\n",
    "        # --- Generator forward ---\n",
    "        _ = generator(z, training=True, return_hard=False)\n",
    "        logits = getattr(generator, \"last_logits\", None)\n",
    "        if logits is not None:\n",
    "            p_fake = tf.nn.softmax(tf.cast(logits, tf.float32), axis=-1)  # [B,1,L,V]\n",
    "        else:\n",
    "            p_fake = tf.cast(generator(z, training=True, return_hard=False), tf.float32)\n",
    "\n",
    "        # --- Discriminator on fake (with features) ---\n",
    "        fake_logits_D, fake_feats = discriminator(\n",
    "            p_fake, training=True, return_features=True\n",
    "        )  # fake_feats: [B, C]\n",
    "\n",
    "        # --- Adversarial loss ---\n",
    "        g_adv = -tf.reduce_mean(fake_logits_D)\n",
    "\n",
    "        # --- Entropy regularization (same as you had) ---\n",
    "        entropy_pos = -tf.reduce_sum(\n",
    "            p_fake * tf.math.log(tf.clip_by_value(p_fake, 1e-8, 1.0)),\n",
    "            axis=-1  # [B,1,L]\n",
    "        )\n",
    "        entropy = tf.reduce_mean(entropy_pos)\n",
    "\n",
    "        g_loss = g_adv - entropy_weight * entropy\n",
    "\n",
    "        # === FEATURE MATCHING LOSS ===\n",
    "        # real_batch should have shape [B,1,L,V] like p_fake.\n",
    "        # If your dataset is tokens, convert to one-hot probs before passing in.\n",
    "        real = tf.cast(tf.expand_dims(real_batch, 1), tf.float32) \n",
    "        _, real_feats = discriminator(\n",
    "            real, training=True, return_features=True\n",
    "        )  # real_feats: [B, C]\n",
    "\n",
    "        # You *usually* want to stop gradients through real features\n",
    "        real_feats = tf.stop_gradient(real_feats)\n",
    "\n",
    "        mean_real = tf.reduce_mean(real_feats, axis=0)  # [C]\n",
    "        mean_fake = tf.reduce_mean(fake_feats, axis=0)  # [C]\n",
    "\n",
    "        fm_loss = tf.reduce_mean(tf.square(mean_real - mean_fake))\n",
    "\n",
    "        g_loss += fm_weight * fm_loss\n",
    "\n",
    "    # --- Apply gradients to G only ---\n",
    "    g_vars = generator.trainable_variables\n",
    "    g_grads = gen_tape.gradient(g_loss, g_vars)\n",
    "    g_missing = _count_missing_grads_t(g_grads)\n",
    "    pairs = [(g, v) for g, v in zip(g_grads, g_vars) if g is not None]\n",
    "    g_optimizer.apply_gradients(pairs)\n",
    "\n",
    "    # EMA after G update (if you use EMA)\n",
    "    ema.update(generator)\n",
    "\n",
    "    g_grad_norm = (\n",
    "        tf.linalg.global_norm([g for g, _ in pairs])\n",
    "        if pairs else tf.constant(0., tf.float32)\n",
    "    )\n",
    "\n",
    "    return g_loss, g_grad_norm, g_missing, entropy, fm_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d3d89b9a-199b-44e8-990c-ac7c986f9dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import csv\n",
    "import re\n",
    "\n",
    "FASTA_PATH = Path(GENS_DIR) / \"generated_sequences.fasta\"\n",
    "INDEX_PATH = Path(GENS_DIR) / \"generated_sequences_index.csv\"\n",
    "\n",
    "# Write CSV header once if file is new\n",
    "if not INDEX_PATH.exists():\n",
    "    with open(INDEX_PATH, \"w\", newline=\"\") as f:\n",
    "        csv.writer(f).writerow([\"step\",\"seq_idx\",\"length\"])\n",
    "        \n",
    "AA = set(\"ACDEFGHIKLMNPQRSTVWYXBZ-\")\n",
    "def sanitize_seq(s: str) -> str:\n",
    "    s = re.sub(r\"\\s+\", \"\", s).upper()\n",
    "    return \"\".join(ch for ch in s if ch in AA)\n",
    "\n",
    "def append_generated_sequences(step: int, sequences):\n",
    "    \"\"\"Append sequences to FASTA + index CSV. Header stores the step + idx.\"\"\"\n",
    "    with open(FASTA_PATH, \"a\") as ffa, open(INDEX_PATH, \"a\", newline=\"\") as fcsv:\n",
    "        w = csv.writer(fcsv)\n",
    "        for i, s in enumerate(sequences):\n",
    "            seq = sanitize_seq(s)\n",
    "            header = f\"step{step:06d}_idx{i}\"\n",
    "            ffa.write(f\">{header}\\n{seq}\\n\")\n",
    "            w.writerow([step, i, len(seq)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4cd7b5f9-792f-4052-914c-08e5cd33d4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "AMINO_ACIDS = \"ACDEFGHIKLMNPQRSTVWY\"  # 20 residues\n",
    "AA_TO_IDX = {aa: i + 1 for i, aa in enumerate(AMINO_ACIDS)}\n",
    "PAD_IDX = 0\n",
    "VOCAB_SIZE = 21  # 0 (PAD) + 1–20\n",
    "\n",
    "MAX_LEN = 160\n",
    "\n",
    "def decode_sequence(onehot):\n",
    "    \"\"\"\n",
    "    Decodes one-hot tensor, removing ALL internal padding (dashes).\n",
    "    Result is a biologically valid contiguous sequence.\n",
    "    \"\"\"\n",
    "    # 1. Get indices (Argmax)\n",
    "    tokens = tf.argmax(onehot, axis=-1).numpy().flatten()\n",
    "    \n",
    "    # 2. Filter out the Padding Index (0) completely\n",
    "    # This removes dashes from start, middle, AND end.\n",
    "    valid_tokens = [t for t in tokens if t != PAD_IDX]\n",
    "    \n",
    "    # 3. Convert indices to Amino Acid characters\n",
    "    # Note: we subtract 1 because your mapping is 1-based (1=A)\n",
    "    seq_str = ''.join([AMINO_ACIDS[i - 1] for i in valid_tokens])\n",
    "    \n",
    "    return seq_str\n",
    "\n",
    "def decode_batch(batch_tensor: tf.Tensor) -> list[str]:\n",
    "    \"\"\"\n",
    "    Decodes a batch of one-hot encoded tensors into amino acid sequences.\n",
    "\n",
    "    Supports input of shape:\n",
    "        - (B, 1, L, 21)\n",
    "        - (B, L, 21)\n",
    "\n",
    "    Returns:\n",
    "        List of decoded strings of length B\n",
    "    \"\"\"\n",
    "    if batch_tensor.shape.rank == 4:\n",
    "        batch_tensor = tf.squeeze(batch_tensor, axis=1)  # (B, L, 21)\n",
    "\n",
    "    return [decode_sequence(seq) for seq in batch_tensor]\n",
    "\n",
    "\n",
    "def encode_sequence(seq):\n",
    "    \"\"\"\n",
    "    Encode a sequence into one-hot with shape [1, MAX_LEN, 21]\n",
    "    \"\"\"\n",
    "    seq = seq.upper()\n",
    "    indices = [AA_TO_IDX.get(aa, PAD_IDX) for aa in seq[:MAX_LEN]]\n",
    "    if len(indices) < MAX_LEN:\n",
    "        indices += [PAD_IDX] * (MAX_LEN - len(indices))\n",
    "    one_hot = tf.one_hot(indices, depth=VOCAB_SIZE, dtype=tf.float32)  # [MAX_LEN, 21]\n",
    "    return tf.expand_dims(one_hot, axis=0)  # [1, MAX_LEN, 21]\n",
    "\n",
    "def encode_batch(sequences):\n",
    "    \"\"\"\n",
    "    Encode a batch of sequences -> [B, 1, MAX_LEN, 21]\n",
    "    \"\"\"\n",
    "    encoded = [encode_sequence(seq) for seq in sequences]\n",
    "    return tf.stack(encoded, axis=0)  # [B, 1, MAX_LEN, 21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1a55a1e3-4770-40bf-a81c-8641cbc1e623",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_aa_distribution(batch):\n",
    "    \"\"\"\n",
    "    Compute normalized amino acid distribution from a one-hot batch,\n",
    "    excluding padding (index 0). Supports shape (B, 1, L, 21) or (B, L, 21).\n",
    "    \"\"\"\n",
    "    if batch.shape.rank == 4:\n",
    "        batch = tf.squeeze(batch, axis=1)  # → (B, L, 21)\n",
    "\n",
    "    batch = tf.cast(batch, tf.float32)\n",
    "    # Exclude padding channel (index 0)\n",
    "    batch = batch[..., 1:]  # → shape: (B, L, 20)\n",
    "\n",
    "    counts = tf.reduce_sum(batch, axis=[0, 1])  # → (20,)\n",
    "    total = tf.reduce_sum(counts)\n",
    "    prob = tf.where(total > 0, counts / total, tf.zeros_like(counts))\n",
    "    return prob.numpy()\n",
    "\n",
    "def js_divergence_per_position(real_batch, gen_batch):\n",
    "    \"\"\"\n",
    "    Computes JS divergence for each position along the sequence (excluding padding index).\n",
    "    Supports input shape (B, 1, L, 21) or (B, L, 21).\n",
    "    Returns: np.array of shape (L,) — JS divergence per position\n",
    "    \"\"\"\n",
    "    if real_batch.shape.rank == 4:\n",
    "        real_batch = tf.squeeze(real_batch, axis=1)\n",
    "    if gen_batch.shape.rank == 4:\n",
    "        gen_batch = tf.squeeze(gen_batch, axis=1)\n",
    "\n",
    "    real_batch = tf.cast(real_batch, tf.float32).numpy()\n",
    "    gen_batch = tf.cast(gen_batch, tf.float32).numpy()\n",
    "\n",
    "    L = real_batch.shape[1]\n",
    "    jsd_pos = []\n",
    "\n",
    "    for i in range(L):\n",
    "        p_real = np.mean(real_batch[:, i, 1:], axis=0)  # exclude padding (index 0)\n",
    "        p_gen = np.mean(gen_batch[:, i, 1:], axis=0)\n",
    "        p_real /= np.sum(p_real) + 1e-8\n",
    "        p_gen /= np.sum(p_gen) + 1e-8\n",
    "        jsd = jensenshannon(p_real, p_gen, base=2)\n",
    "        jsd_pos.append(jsd)\n",
    "    \n",
    "    return np.array(jsd_pos)\n",
    "\n",
    "def sequence_lengths(onehot_batch):\n",
    "    indices = tf.argmax(onehot_batch, axis=-1)\n",
    "    non_padding = tf.not_equal(indices, 0)\n",
    "    return tf.reduce_sum(tf.cast(non_padding, tf.int32), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8a37eb7c-d89d-4304-b1ce-ba13017cbe70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalized_hamming_distance(seq1, seq2):\n",
    "    \"\"\"Compute normalized Hamming distance between two equal-length strings.\"\"\"\n",
    "    assert len(seq1) == len(seq2), \"Sequences must be the same length\"\n",
    "    return sum(a != b for a, b in zip(seq1, seq2)) / len(seq1)\n",
    "\n",
    "def filter_diverse_sequences(sequences, threshold=0.05, max_count=None):\n",
    "    diverse = []\n",
    "    for seq in sequences:\n",
    "        if all(normalized_hamming_distance(seq, d) >= threshold for d in diverse):\n",
    "            diverse.append(seq)\n",
    "        if max_count is not None and len(diverse) >= max_count:\n",
    "            break\n",
    "    return diverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d7ce38a1-383e-4f18-a76d-f00526421cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally pass amino acid sequence if you want labels\n",
    "def save_attention_png(attn, filename=\"attn_map.png\", aa_seq=None):\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    plt.imshow(attn, cmap='viridis')\n",
    "    plt.title(\"Attention Heatmap\")\n",
    "    if aa_seq:\n",
    "        plt.xticks(ticks=range(len(aa_seq)), labels=list(aa_seq), fontsize=6, rotation=90)\n",
    "        plt.yticks(ticks=range(len(aa_seq)), labels=list(aa_seq), fontsize=6)\n",
    "    else:\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filename)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "02600cd7-8e4b-4e06-be87-b959ac54b7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_attention_to_disk(attn_scores, sequences, step, output_dir=\"attn_logs\"):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    for i in range(attn_scores.shape[0]):\n",
    "        sample_path = os.path.join(output_dir, f\"sample_{i}_step_{step}.npz\")\n",
    "        np.savez_compressed(sample_path,\n",
    "                            attn=attn_scores[i].numpy(),  # shape [H, W, W]\n",
    "                            sequence=sequences[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "59b88631-e295-4874-b7f4-431081850047",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_attention_to_tensorboard(attn_scores, sequences, step, summary_writer):\n",
    "    \"\"\"\n",
    "    attn_scores: Tensor [B, H, W, W]\n",
    "    sequences: list of strings\n",
    "    \"\"\"\n",
    "    B, H, W, _ = attn_scores.shape\n",
    "    attn_scores = attn_scores.numpy()  # Convert for plotting\n",
    "    with summary_writer.as_default():\n",
    "        for i in range(min(B, 2)):  # log up to 2 samples\n",
    "            for h in range(H):\n",
    "                fig, ax = plt.subplots(figsize=(6, 6), dpi=100)\n",
    "                attn = attn_scores[i, h]  # [W, W]\n",
    "                im = ax.imshow(attn, cmap='magma', vmin=0.0, vmax=1.0)\n",
    "\n",
    "                ax.set_title(f\"Sample {i}, Head {h}\")\n",
    "                ax.set_xlabel(\"Residue Index\")\n",
    "                ax.set_ylabel(\"Residue Index\")\n",
    "\n",
    "                # Show ticks every 20 residues for readability\n",
    "                tick_positions = np.arange(0, W, 20)\n",
    "                ax.set_xticks(tick_positions)\n",
    "                ax.set_yticks(tick_positions)\n",
    "\n",
    "                # Optional: sequence length overlay\n",
    "                seq_len = len(sequences[i].replace(\"-\", \"\"))\n",
    "                ax.axvline(seq_len, color='white', linestyle='--', linewidth=1)\n",
    "                ax.axhline(seq_len, color='white', linestyle='--', linewidth=1)\n",
    "\n",
    "                plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "                plt.tight_layout()\n",
    "\n",
    "                # Save to TensorBoard\n",
    "                buf = io.BytesIO()\n",
    "                plt.savefig(buf, format='png')\n",
    "                plt.close(fig)\n",
    "                buf.seek(0)\n",
    "\n",
    "                image = tf.image.decode_png(buf.getvalue(), channels=4)\n",
    "                image = tf.expand_dims(image, 0)\n",
    "                tf.summary.image(f\"AttentionMaps/Sample{i}_Head{h}\", image, step=step)\n",
    "\n",
    "            tf.summary.text(f\"Attention/Sequence_{i}\", tf.convert_to_tensor([sequences[i]]), step=step)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f7c89612-ede3-462c-b597-53d4f818dc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- ESM eval setup (PyTorch) ---\n",
    "import torch, numpy as np, matplotlib.pyplot as plt\n",
    "from scipy.linalg import sqrtm\n",
    "import umap\n",
    "import esm\n",
    "\n",
    "# Config knobs (can be FLAGS if you prefer)\n",
    "ESM_MODEL_NAME = getattr(FLAGS, \"esm_model\", \"esm2_t6_8M_UR50D\")  # small & fast\n",
    "ESM_DEVICE     = getattr(FLAGS, \"esm_device\", \"cuda\")              # \"cpu\" is safe with TF; use \"cuda\" if you want\n",
    "ESM_BATCH      = getattr(FLAGS, \"esm_batch\", 64)\n",
    "ESM_EVAL_N     = getattr(FLAGS, \"esm_eval_n\", 128)                # sequences per class (real/gen) per eval\n",
    "\n",
    "# Load ESM once\n",
    "def _load_esm(name: str):\n",
    "    name = name.strip()\n",
    "    if name == \"esm2_t6_8M_UR50D\":\n",
    "        m, A = esm.pretrained.esm2_t6_8M_UR50D(); layer = 6\n",
    "    elif name == \"esm2_t12_35M_UR50D\":\n",
    "        m, A = esm.pretrained.esm2_t12_35M_UR50D(); layer = 12\n",
    "    else:\n",
    "        m, A = esm.pretrained.esm2_t6_8M_UR50D(); layer = 6\n",
    "    return m.eval(), A, layer\n",
    "\n",
    "_ESM_MODEL, _ESM_ALPH, _ESM_LAYER = _load_esm(ESM_MODEL_NAME)\n",
    "\n",
    "# mean-pooled ESM embeddings from sequences (list[str])\n",
    "def esm_embed(seqs, model=_ESM_MODEL, alphabet=_ESM_ALPH, layer=_ESM_LAYER,\n",
    "              batch_size=ESM_BATCH, device=ESM_DEVICE):\n",
    "    model = model.to(device)\n",
    "    bc = alphabet.get_batch_converter()\n",
    "    vecs = []\n",
    "    for i in range(0, len(seqs), batch_size):\n",
    "        chunk = seqs[i:i+batch_size]\n",
    "        labels, strs, toks = bc([(\"seq\", s) for s in chunk])\n",
    "        toks = toks.to(device)\n",
    "        with torch.no_grad():\n",
    "            out = model(toks, repr_layers=[layer])\n",
    "            rep = out[\"representations\"][layer][:, 1:-1, :].mean(1)  # drop CLS/EOS, mean over tokens\n",
    "        vecs.append(rep.detach().cpu().numpy())\n",
    "    return np.vstack(vecs) if vecs else np.zeros((0, 0), dtype=np.float32)\n",
    "\n",
    "def frechet(mu1, C1, mu2, C2, eps=1e-6):\n",
    "    C1 = C1 + np.eye(C1.shape[0]) * eps\n",
    "    C2 = C2 + np.eye(C2.shape[0]) * eps\n",
    "    diff = (mu1 - mu2)\n",
    "    covmean = sqrtm(C1.dot(C2))\n",
    "    if np.iscomplexobj(covmean): covmean = covmean.real\n",
    "    return float(diff.dot(diff) + np.trace(C1 + C2 - 2 * covmean))\n",
    "\n",
    "def esm_fid(E_real, E_gen):\n",
    "    if len(E_real)==0 or len(E_gen)==0: return np.nan\n",
    "    mu_r, C_r = E_real.mean(0), np.cov(E_real, rowvar=False)\n",
    "    mu_g, C_g = E_gen.mean(0), np.cov(E_gen, rowvar=False)\n",
    "    return frechet(mu_r, C_r, mu_g, C_g)\n",
    "\n",
    "def _fig_to_img(fig, close=True):\n",
    "    fig.canvas.draw()\n",
    "    w, h = fig.canvas.get_width_height()\n",
    "    img = np.frombuffer(fig.canvas.tostring_rgb(), dtype=np.uint8).reshape(h, w, 3)\n",
    "    if close: plt.close(fig)\n",
    "    return img\n",
    "\n",
    "def esm_umap_image(E_real, E_gen, title=\"UMAP (ESM) Real vs Gen\"):\n",
    "    if len(E_real)==0 or len(E_gen)==0:\n",
    "        return None\n",
    "    mapper = umap.UMAP(n_neighbors=30, min_dist=0.1, metric=\"cosine\", random_state=0)\n",
    "    Zr = mapper.fit_transform(E_real)\n",
    "    Zg = mapper.transform(E_gen)\n",
    "    fig = plt.figure(figsize=(5, 4))\n",
    "    plt.scatter(Zr[:,0], Zr[:,1], s=6, alpha=0.30, label=\"Real\")\n",
    "    plt.scatter(Zg[:,0], Zg[:,1], s=8, alpha=0.70, label=\"Gen\")\n",
    "    plt.legend(loc=\"best\"); plt.title(title); plt.tight_layout()\n",
    "    return _fig_to_img(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3f541a05-4250-4915-a23b-3ae14921f373",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_generated_sequences(g_model, z_dim, decode_batch_fn, target_n, per_call=128):\n",
    "    seqs = []\n",
    "    while len(seqs) < target_n:\n",
    "        z = tf.random.normal([min(per_call, target_n - len(seqs)), z_dim], dtype=tf.float32)\n",
    "        hard = g_model(z, training=False, return_hard=True)\n",
    "        hard = tf.squeeze(hard, axis=1)\n",
    "        seqs.extend(decode_batch_fn(hard))\n",
    "    return seqs[:target_n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cd861ca5-27dd-4508-ab4f-2e787458b14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "real_df = pd.read_csv(\"/home1/ZZHANG201@kgi.edu/GAN/zzGAN/gan/data/zz/sample_seqs.csv\")\n",
    "real_seqs = real_df[\"sequence\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ac1f7f2a-fdbc-496a-aa16-272f999031ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Diagnostics helpers ---\n",
    "def current_lr(opt):\n",
    "    \"\"\"Return a Python float for the optimizer LR regardless of schedule/variable/float.\"\"\"\n",
    "    lr = getattr(opt, \"lr\", None) or getattr(opt, \"learning_rate\", None)\n",
    "    try:\n",
    "        return float(tf.keras.backend.get_value(lr))\n",
    "    except Exception:\n",
    "        # e.g., schedules\n",
    "        return float(tf.keras.backend.get_value(lr(tf.cast(model.g_model.global_step, tf.float32))))\n",
    "\n",
    "def _count_missing_grads_t(grads):\n",
    "    # Tensor int32 count of None grads (safe inside @tf.function)\n",
    "    return tf.reduce_sum(tf.constant([1 if g is None else 0 for g in grads], dtype=tf.int32))\n",
    "\n",
    "for l in model.g_model.layers:\n",
    "    if hasattr(l, \"disable_sn\"):\n",
    "        l.disable_sn.assign(False)   # True to disable sn for debugging or False to re-enable\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22fa27a-5148-42b7-8f6b-b39ee255a729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[177799] Generator Loss: 29.5090, Discriminator Loss: -11.6845\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "real_iter = iter(dataset)\n",
    "d_prev_k = None                       # for kernel delta probe\n",
    "ESM_EVAL_N = 512                      # adjust if you want more/less for FID\n",
    "\n",
    "# === Training Loop ===\n",
    "for step in range(FLAGS.steps):\n",
    "    # --- D:G ratio schedule ---\n",
    "    d_step = 1 if step < FLAGS.multid_schedule else FLAGS.d_step\n",
    "\n",
    "    # --- Discriminator steps ---\n",
    "    for _ in range(d_step):\n",
    "        real_batch = next(real_iter)\n",
    "        d_loss, d_grad_norm, d_wgan, d_gp, d_missing, d_real_m, d_fake_m = train_discriminator_step(\n",
    "            model.g_model, model.d_model, model.d_optim, real_batch, FLAGS.z_dim\n",
    "        )\n",
    "\n",
    "    # --- Generator step ---\n",
    "    g_loss, g_grad_norm, g_missing, g_entropy, fm_loss = train_generator_step(\n",
    "        model.g_model, model.d_model,\n",
    "        model.g_optim, FLAGS.z_dim,\n",
    "        real_batch=real_batch,\n",
    "        entropy_weight=0.01,\n",
    "        fm_weight=FLAGS.fm_weight\n",
    "    )\n",
    "\n",
    "    model.global_step.assign_add(1)\n",
    "\n",
    "    # === Light logging (every 100 steps) ===\n",
    "    if (step + 1) % 100 == 0 or step == FLAGS.steps - 1:\n",
    "        clear_output(wait=True)\n",
    "        print(f\"[{step}] Generator Loss: {g_loss:.4f}, Discriminator Loss: {d_loss:.4f}\")\n",
    "        with summary_writer.as_default():\n",
    "            # D losses\n",
    "            tf.summary.scalar(\"D/total\",      d_loss,    step=step)\n",
    "            tf.summary.scalar(\"D/wgan\",       d_wgan,    step=step)\n",
    "            tf.summary.scalar(\"D/gp\",         d_gp,      step=step)\n",
    "            # G losses\n",
    "            tf.summary.scalar(\"G/total\",      g_loss,    step=step)\n",
    "            tf.summary.scalar(\"G/entropy\",    g_entropy, step=step)\n",
    "            tf.summary.scalar(\"G/feat_match\", fm_loss, step=step)\n",
    "            # Grad norms & missing counts\n",
    "            tf.summary.scalar(\"D/grad_norm\", d_grad_norm, step=step)\n",
    "            tf.summary.scalar(\"G/grad_norm\", g_grad_norm, step=step)\n",
    "            tf.summary.scalar(\"D/missing_grads\", d_missing, step=step)\n",
    "            tf.summary.scalar(\"G/missing_grads\", g_missing, step=step)\n",
    "            # LRs\n",
    "            tf.summary.scalar(\"LR/D\", current_lr(model.d_optim), step=step)\n",
    "            tf.summary.scalar(\"LR/G\", current_lr(model.g_optim), step=step)\n",
    "            # D logits means\n",
    "            tf.summary.scalar(\"D/real_logit_mean\", d_real_m, step=step)\n",
    "            tf.summary.scalar(\"D/fake_logit_mean\", d_fake_m, step=step)\n",
    "\n",
    "    # === Heavier probes (every 1000 steps) ===\n",
    "    if (step + 1) % 1000 == 0 or step == FLAGS.steps - 1:\n",
    "        try:\n",
    "            k = model.d_model.get_layer(\"conv1\").kernel\n",
    "            delta = tf.constant(0.0, tf.float32)\n",
    "            if d_prev_k is not None:\n",
    "                delta = tf.norm(tf.cast(k, tf.float32) - tf.cast(d_prev_k, tf.float32))\n",
    "            d_prev_k = tf.identity(k)  # snapshot for next time\n",
    "            with summary_writer.as_default():\n",
    "                tf.summary.scalar(\"D/conv1_kernel_delta\", delta, step=step)\n",
    "        except Exception:\n",
    "            pass\n",
    "        # Generated sequence preview\n",
    "        z = tf.random.normal([8, FLAGS.z_dim], dtype=tf.float32)\n",
    "        samples = model.g_model(z, training=False, return_hard=True, return_attention=True)\n",
    "        samples = tf.squeeze(samples, axis=1)\n",
    "        sequences = [decode_sequence(seq) for seq in samples]\n",
    "        append_generated_sequences(step=step, sequences=sequences)\n",
    "\n",
    "        attn_scores = model.g_model.last_attn_scores\n",
    "        save_attention_to_disk(attn_scores, sequences, step, output_dir=attn_dir)\n",
    "        tf.print(\"\\n\".join(f\"Sample {i}: {sequences[i]}...\" for i in range(len(sequences))))\n",
    "\n",
    "    # === Quality metrics (every 500 steps) ===\n",
    "    if (step + 1) % 1000 == 0 or step == FLAGS.steps - 1:\n",
    "        # fresh batches for metrics (don’t rely on prior scope variables)\n",
    "        z = tf.random.normal([64, FLAGS.z_dim], dtype=tf.float32)\n",
    "        hard_batch = model.g_model(z, training=False, return_hard=True)\n",
    "        real_batch = next(real_iter)\n",
    "\n",
    "        gen_seqs  = decode_batch(hard_batch)\n",
    "        real_seqs = decode_batch(real_batch)\n",
    "\n",
    "        fr_loss, cdr_loss = quality_losses(gen_seqs, real_seqs, full_real_frs_csv=\"data/vh_regions.csv\")\n",
    "        anarci_stats = anarci_quality_log(gen_seqs)\n",
    "\n",
    "        p_gen  = get_aa_distribution(hard_batch)\n",
    "        p_real = get_aa_distribution(real_batch)\n",
    "        jsd    = jensenshannon(p_real, p_gen, base=2)\n",
    "\n",
    "        real_lengths = sequence_lengths(real_batch)\n",
    "        gen_lengths  = sequence_lengths(hard_batch)\n",
    "        jsd_pos      = js_divergence_per_position(real_batch, hard_batch)\n",
    "        valid_jsd    = jsd_pos[~np.isnan(jsd_pos)]\n",
    "        length_diff  = tf.reduce_mean(tf.cast(gen_lengths, tf.float32)) - tf.reduce_mean(tf.cast(real_lengths, tf.float32))\n",
    "\n",
    "        with summary_writer.as_default():\n",
    "            tf.summary.scalar(\"JS_Divergence/Aggregated\", jsd, step=step)\n",
    "            tf.summary.histogram(\"JS_Divergence/Per_Position\", jsd_pos, step=step)\n",
    "            tf.summary.scalar(\"JS_Divergence/Per_Position_Mean\", float(np.mean(valid_jsd)), step=step)\n",
    "            tf.summary.scalar(\"JS_Divergence/Per_Position_Max\",  float(np.max(valid_jsd)),  step=step)\n",
    "            tf.summary.scalar(\"JS_Divergence/Per_Position_Std\",  float(np.std(valid_jsd)),  step=step)\n",
    "\n",
    "            tf.summary.scalar(\"Length/Real_mean\",      tf.reduce_mean(real_lengths), step=step)\n",
    "            tf.summary.scalar(\"Length/Generated_mean\", tf.reduce_mean(gen_lengths),  step=step)\n",
    "            tf.summary.scalar(\"Length/Generated_stddev\", tf.math.reduce_std(tf.cast(gen_lengths, tf.float32)), step=step)\n",
    "            tf.summary.scalar(\"Length/Diff_Gen_minus_Real\", length_diff, step=step)\n",
    "\n",
    "            tf.summary.scalar(\"Anarci/FR_Loss\",      fr_loss, step=step)\n",
    "            tf.summary.scalar(\"Anarci/CDR_JS_Loss\",  cdr_loss, step=step)\n",
    "            tf.summary.scalar(\"Anarci/AnyHit\",       anarci_stats[\"full_hit\"] + anarci_stats[\"partial_hit\"], step=step)\n",
    "            tf.summary.scalar(\"Anarci/FullHit\",      anarci_stats[\"full_hit\"],     step=step)\n",
    "            tf.summary.scalar(\"Anarci/PartialHit\",   anarci_stats[\"partial_hit\"],  step=step)\n",
    "            tf.summary.scalar(\"Anarci/NoHit\",        anarci_stats[\"no_hit\"],       step=step)\n",
    "\n",
    "    # === Checkpointing ===\n",
    "    if (step + 1) % FLAGS.save_checkpoint_sec == 0 or step == FLAGS.steps - 1:\n",
    "        path = ckpt_manager.save()\n",
    "        print(f\"Checkpoint saved at step {step}: {path}\")\n",
    "\n",
    "    # === ESM eval (EMA), every 2500 steps ===\n",
    "    if (step + 1) % 2500 == 0 or step == FLAGS.steps - 1:\n",
    "        # Assemble fresh real/gen sets here so variables exist\n",
    "        # (don’t rely on `real_seqs` from another block)\n",
    "        # Real:\n",
    "        real_eval_batch = next(real_iter)\n",
    "        real_eval_seqs  = decode_batch(real_eval_batch)\n",
    "        # Gen (EMA weights):\n",
    "        with ema.average_parameters(model.g_model):\n",
    "            gen_eval_seqs = sample_generated_sequences(model.g_model, FLAGS.z_dim, decode_batch, ESM_EVAL_N)\n",
    "\n",
    "        E_r = esm_embed(real_eval_seqs)\n",
    "        E_g = esm_embed(gen_eval_seqs)\n",
    "        fid_esm = esm_fid(E_r, E_g)\n",
    "        umap_img = esm_umap_image(E_r, E_g, title=\"UMAP (ESM) Real vs Gen (EMA)\")\n",
    "\n",
    "        with summary_writer.as_default():\n",
    "            tf.summary.scalar(\"ESM/FID_EMA\", fid_esm, step=step)\n",
    "            if umap_img is not None:\n",
    "                tf.summary.image(\"UMAP_ESM/Real_vs_Gen_EMA\", umap_img[None, ...], step=step)\n",
    "\n",
    "    # === Finalization ===\n",
    "    if step == FLAGS.steps - 1:\n",
    "        with ema.average_parameters(model.g_model):\n",
    "            z = tf.random.normal([300, FLAGS.z_dim], dtype=tf.float32)\n",
    "            hard_batch = model.g_model(z, training=False, return_hard=True, return_attention=True)\n",
    "            hard_batch = tf.squeeze(hard_batch, axis=1)\n",
    "            sequences = [decode_sequence(seq) for seq in hard_batch]\n",
    "\n",
    "            diverse_seqs = filter_diverse_sequences(sequences, threshold=0.05, max_count=None)\n",
    "\n",
    "            # save a few attention maps\n",
    "            for i in range(min(4, len(sequences))):\n",
    "                for h in range(2):\n",
    "                    if model.g_model.last_attn_scores is not None:\n",
    "                        attn = model.g_model.last_attn_scores[i, h]  # [L, L]\n",
    "                        save_attention_png(attn.numpy(), filename=f\"attn_sample{i}_head{h}.png\", aa_seq=sequences[i])\n",
    "\n",
    "            with summary_writer.as_default():\n",
    "                for i, seq in enumerate(diverse_seqs[:30]):\n",
    "                    tf.summary.text(f\"Final/DiverseSequence_{i}\", tf.convert_to_tensor([seq]), step=step)\n",
    "                tf.summary.scalar(\"Final/NumDiverseSequences\", len(diverse_seqs), step=step)\n",
    "\n",
    "            print(f\"Generated {len(sequences)} sequences.\")\n",
    "            print(f\"Found {len(diverse_seqs)} diverse sequences.\")\n",
    "\n",
    "        summary_writer.flush()\n",
    "        generate_dynamic_layout(logdir=os.path.join(FLAGS.logdir, FLAGS.name), run_name=timestamp)\n",
    "        print(f\"Layout updated based on {log_dir}\")\n",
    "\n",
    "        final_path = ckpt_manager.save()\n",
    "        print(\"Final checkpoint saved:\", final_path)\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32551f7d-9301-475d-b1d5-c463905c9583",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd87f52-45a3-4293-a7f2-2d6cab8463b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python (tf2_16)",
   "language": "python",
   "name": "tf2_16"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
